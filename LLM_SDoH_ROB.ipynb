{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xUqC1HYXy0sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd396a1-7b23-4a26-d925-39a6768c0f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-be7afa9bfac6>:427: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax2.set_yticklabels(['' for _ in range(len(data['df_sorted']))])\n",
            "<ipython-input-24-be7afa9bfac6>:428: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax3.set_yticklabels(['' for _ in range(len(data['df_sorted']))])\n",
            "<ipython-input-24-be7afa9bfac6>:475: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
            "  plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset has 35 studies\n",
            "Number of unique (x,y) coordinates: 15\n",
            "All visualizations have been generated successfully.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "# Install adjustText if not available\n",
        "try:\n",
        "    from adjustText import adjust_text\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"adjustText\"])\n",
        "    from adjustText import adjust_text\n",
        "\n",
        "#########################################\n",
        "# CONFIGURATION AND STYLING\n",
        "#########################################\n",
        "\n",
        "class PlotStyle:\n",
        "    \"\"\"Class to manage plot styling and color palettes\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.color_palette = {\n",
        "            'High Risk': '#e41a1c',     # Bright red (Nature standard)\n",
        "            'Medium Risk': '#ff9900',   # Orange (Nature standard)\n",
        "            'Low Risk': '#4daf4a',      # Green (Nature standard)\n",
        "            'primary_blue': '#377eb8',  # Nature standard blue\n",
        "            'secondary_blue': '#80b1d3', # Lighter blue\n",
        "            'light_blue': '#deebf7',    # Very light blue\n",
        "            'background': '#ffffff',    # White background\n",
        "            'grid': '#e6e6e6',          # Light gray grid\n",
        "            'text': '#3c3c3c',          # Dark gray text\n",
        "            'accent1': '#984ea3',       # Purple (Nature standard)\n",
        "            'accent2': '#a65628',       # Brown (Nature standard)\n",
        "            'accent3': '#f781bf'        # Pink (Nature standard)\n",
        "        }\n",
        "\n",
        "        self.risk_cmap = self._create_risk_colormap()\n",
        "        self._set_plot_parameters()\n",
        "\n",
        "    def _create_risk_colormap(self):\n",
        "        \"\"\"Create colormap from red to yellow to green for heatmaps\"\"\"\n",
        "        return LinearSegmentedColormap.from_list(\n",
        "            'risk_cmap',\n",
        "            [(0.0, self.color_palette['High Risk']),\n",
        "             (0.5, self.color_palette['Medium Risk']),\n",
        "             (1.0, self.color_palette['Low Risk'])],\n",
        "            N=100\n",
        "        )\n",
        "\n",
        "    def _set_plot_parameters(self):\n",
        "        \"\"\"Set global matplotlib parameters for Nature style\"\"\"\n",
        "        plt.rcParams.update({\n",
        "            'axes.titlesize': 9,\n",
        "            'axes.titleweight': 'bold',\n",
        "            'axes.labelsize': 8,\n",
        "            'xtick.labelsize': 7,\n",
        "            'ytick.labelsize': 7,\n",
        "            'legend.fontsize': 7,\n",
        "            'figure.facecolor': self.color_palette['background'],\n",
        "            'axes.facecolor': self.color_palette['background'],\n",
        "            'figure.figsize': (3.5, 2.5),\n",
        "            'axes.grid': False,\n",
        "            'grid.color': self.color_palette['grid'],\n",
        "            'grid.alpha': 0.5,\n",
        "            'axes.linewidth': 0.5,\n",
        "            'xtick.major.width': 0.5,\n",
        "            'ytick.major.width': 0.5,\n",
        "            'lines.linewidth': 1.0,\n",
        "            'lines.markersize': 3,\n",
        "            'savefig.dpi': 300,\n",
        "            'savefig.format': 'pdf',\n",
        "            'savefig.bbox': 'tight',\n",
        "            'savefig.transparent': False\n",
        "        })\n",
        "\n",
        "#########################################\n",
        "# DATA PREPARATION\n",
        "#########################################\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Class to process and prepare data for visualization\"\"\"\n",
        "\n",
        "    def __init__(self, study_data):\n",
        "        \"\"\"\n",
        "        Initialize with study data dictionary containing:\n",
        "        - studies: List of study names\n",
        "        - categories: List of assessment categories\n",
        "        - priority_levels: List of priority levels for each category\n",
        "        - max_points: List of maximum points for each category\n",
        "        - scores: Dictionary of scores for each category\n",
        "        \"\"\"\n",
        "        self.study_data = study_data\n",
        "        self.processed_data = self._process_data()\n",
        "\n",
        "    def _process_data(self):\n",
        "        \"\"\"Process the raw data into a structured format\"\"\"\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(self.study_data['scores'])\n",
        "        df['Study'] = self.study_data['studies']\n",
        "\n",
        "        # Extract risk matrix\n",
        "        risk_matrix = np.array(df[self.study_data['categories']])\n",
        "\n",
        "        # Group categories by priority level\n",
        "        high_priority_indices = [i for i, level in enumerate(self.study_data['priority_levels']) if level == \"High\"]\n",
        "        medium_priority_indices = [i for i, level in enumerate(self.study_data['priority_levels']) if level == \"Medium\"]\n",
        "        standard_priority_indices = [i for i, level in enumerate(self.study_data['priority_levels']) if level == \"Standard\"]\n",
        "\n",
        "        # Calculate scores\n",
        "        high_priority_scores = risk_matrix[:, high_priority_indices].sum(axis=1)\n",
        "        medium_priority_scores = risk_matrix[:, medium_priority_indices].sum(axis=1)\n",
        "        standard_priority_scores = risk_matrix[:, standard_priority_indices].sum(axis=1)\n",
        "        total_scores = risk_matrix.sum(axis=1)\n",
        "\n",
        "        # Determine risk levels based on framework criteria\n",
        "        risk_levels = []\n",
        "        for i in range(len(self.study_data['studies'])):\n",
        "            if (total_scores[i] >= 14 and high_priority_scores[i] >= 6 and medium_priority_scores[i] >= 3):\n",
        "                risk_levels.append(\"Low Risk\")\n",
        "            elif (total_scores[i] >= 9 and high_priority_scores[i] >= 4 and medium_priority_scores[i] >= 2):\n",
        "                risk_levels.append(\"Medium Risk\")\n",
        "            else:\n",
        "                risk_levels.append(\"High Risk\")\n",
        "\n",
        "        # Add calculated values to DataFrame\n",
        "        df[\"High Priority Score\"] = high_priority_scores\n",
        "        df[\"Medium Priority Score\"] = medium_priority_scores\n",
        "        df[\"Standard Priority Score\"] = standard_priority_scores\n",
        "        df[\"Total Score\"] = total_scores\n",
        "        df[\"Risk Level\"] = risk_levels\n",
        "\n",
        "        # Calculate maximum possible scores\n",
        "        max_high_priority = sum([self.study_data['max_points'][i] for i in high_priority_indices])\n",
        "        max_medium_priority = sum([self.study_data['max_points'][i] for i in medium_priority_indices])\n",
        "        max_standard_priority = sum([self.study_data['max_points'][i] for i in standard_priority_indices])\n",
        "        max_total = sum(self.study_data['max_points'])\n",
        "\n",
        "        # Create normalized matrix for visualization\n",
        "        normalized_matrix = np.zeros((len(df), len(self.study_data['categories'])))\n",
        "        for i, cat in enumerate(self.study_data['categories']):\n",
        "            normalized_matrix[:, i] = df[cat].values / self.study_data['max_points'][i]\n",
        "\n",
        "        # Sort studies by total score\n",
        "        df_sorted = df.sort_values(by=\"Total Score\", ascending=False)\n",
        "\n",
        "        # Create normalized matrix for sorted data\n",
        "        sorted_normalized_matrix = np.zeros((len(df_sorted), len(self.study_data['categories'])))\n",
        "        for i, cat in enumerate(self.study_data['categories']):\n",
        "            sorted_normalized_matrix[:, i] = df_sorted[cat].values / self.study_data['max_points'][i]\n",
        "\n",
        "        return {\n",
        "            'df': df,\n",
        "            'df_sorted': df_sorted,\n",
        "            'risk_matrix': risk_matrix,\n",
        "            'normalized_matrix': normalized_matrix,\n",
        "            'sorted_normalized_matrix': sorted_normalized_matrix,\n",
        "            'categories': self.study_data['categories'],\n",
        "            'studies': self.study_data['studies'],\n",
        "            'priority_levels': self.study_data['priority_levels'],\n",
        "            'max_points': self.study_data['max_points'],\n",
        "            'high_priority_indices': high_priority_indices,\n",
        "            'medium_priority_indices': medium_priority_indices,\n",
        "            'standard_priority_indices': standard_priority_indices,\n",
        "            'max_high_priority': max_high_priority,\n",
        "            'max_medium_priority': max_medium_priority,\n",
        "            'max_standard_priority': max_standard_priority,\n",
        "            'max_total': max_total\n",
        "        }\n",
        "\n",
        "#########################################\n",
        "# VISUALIZATION FUNCTIONS\n",
        "#########################################\n",
        "\n",
        "class Visualizer:\n",
        "    \"\"\"Class containing all visualization functions\"\"\"\n",
        "\n",
        "    def __init__(self, style):\n",
        "        self.style = style\n",
        "\n",
        "    def plot_domain_completion(self, data):\n",
        "        \"\"\"Creates stacked bar chart of domain completion rates\"\"\"\n",
        "        plt.figure(figsize=(6.5, 3.5), facecolor=self.style.color_palette['background'])\n",
        "\n",
        "        # Calculate completion percentage for each domain\n",
        "        completion_percent = []\n",
        "        for i, cat in enumerate(data['categories']):\n",
        "            total_points = data['df'][cat].sum()\n",
        "            max_possible_points = data['max_points'][i] * len(data['studies'])\n",
        "            percent = (total_points / max_possible_points) * 100\n",
        "            completion_percent.append(percent)\n",
        "\n",
        "        # Create DataFrame for stacked bar\n",
        "        df_stacked = pd.DataFrame({\n",
        "            'Domain': data['categories'],\n",
        "            'Completion (%)': completion_percent,\n",
        "            'Missing (%)': [100 - p for p in completion_percent],\n",
        "            'Priority': data['priority_levels'],\n",
        "            'Max Points': data['max_points']\n",
        "        })\n",
        "\n",
        "        # Sort by priority level and completion percentage\n",
        "        priority_order = {\"High\": 0, \"Medium\": 1, \"Standard\": 2}\n",
        "        df_stacked['Priority Order'] = df_stacked['Priority'].map(priority_order)\n",
        "        df_stacked = df_stacked.sort_values(['Priority Order', 'Completion (%)'], ascending=[True, False])\n",
        "\n",
        "        # Create stacked bars\n",
        "        plt.barh(df_stacked['Domain'], df_stacked['Completion (%)'],\n",
        "            color=self.style.color_palette['Low Risk'], label='Complete', alpha=0.8, height=0.6)\n",
        "        plt.barh(df_stacked['Domain'], df_stacked['Missing (%)'],\n",
        "            left=df_stacked['Completion (%)'], color=self.style.color_palette['High Risk'],\n",
        "            label='Missing', alpha=0.8, height=0.6)\n",
        "\n",
        "        # Add annotations\n",
        "        for i, (domain, priority, points) in enumerate(zip(df_stacked['Domain'], df_stacked['Priority'], df_stacked['Max Points'])):\n",
        "            plt.text(101, i, f'{priority} ({points}pts)', va='center', fontsize=6)\n",
        "\n",
        "        # Add separator lines between priority groups\n",
        "        priority_groups = df_stacked.groupby('Priority Order')\n",
        "        cumulative_count = 0\n",
        "        for name, group in priority_groups:\n",
        "            if name > 0:  # Don't add a line before the first group\n",
        "                plt.axhline(y=cumulative_count - 0.5, color='black', linestyle='-', alpha=0.3, linewidth=0.5)\n",
        "            cumulative_count += len(group)\n",
        "\n",
        "        # Finalize plot\n",
        "        plt.xlim(0, 120)\n",
        "        plt.xlabel('Percentage of Maximum Possible Points (%)', fontsize=8)\n",
        "        plt.title('Domain Completion Rate by Priority Level', fontsize=9, fontweight='bold')\n",
        "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, fontsize=7)\n",
        "        plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('domain_completion_by_priority.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('domain_completion_by_priority.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_risk_assessment_heatmap(self, data):\n",
        "        \"\"\"Creates traffic light visualization with circles sized by domain max points\"\"\"\n",
        "        # Adjust figure dimensions - narrower width, taller height\n",
        "        combined_fig = plt.figure(figsize=(5, 17), facecolor=self.style.color_palette['background'])\n",
        "\n",
        "        # Update grid proportions with more height\n",
        "        grid = plt.GridSpec(2, 21, height_ratios=[20, 1], hspace=0.4)\n",
        "\n",
        "        # Create subplots with adjusted widths\n",
        "        ax1 = combined_fig.add_subplot(grid[0, :11])  # Main visualization\n",
        "        ax2 = combined_fig.add_subplot(grid[0, 12:17])  # Priority scores\n",
        "        ax3 = combined_fig.add_subplot(grid[0, 19:])  # Total score column\n",
        "        legend_ax = combined_fig.add_subplot(grid[1, :])  # Legend at bottom\n",
        "        legend_ax.axis('off')  # Hide axis for legend\n",
        "\n",
        "        # Significantly increase the y-axis limits to create more space between rows\n",
        "        num_studies = len(data['df_sorted'])\n",
        "        y_padding = 0.8  # Greatly increased padding between rows\n",
        "\n",
        "        # Set up the axes with increased spacing\n",
        "        ax1.set_xlim(-0.5, len(data['categories'])-0.5)\n",
        "        ax1.set_ylim(-0.5 - y_padding, num_studies-0.5 + y_padding)\n",
        "\n",
        "        # Add dotted light grid lines to main visualization\n",
        "        ax1.set_axisbelow(True)\n",
        "        ax1.grid(which='both', linestyle=':', linewidth=0.5, color='#cccccc', alpha=0.7)\n",
        "\n",
        "        # For even more readability - add alternating row shading with increased height\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            if i % 2 == 0:  # Even rows\n",
        "                ax1.axhspan(i-0.5 - y_padding/2, i+0.5 + y_padding/2, color='#f5f5f5', alpha=0.3, zorder=0)\n",
        "\n",
        "        # Adjust circle size - INCREASED from previous version\n",
        "        base_size = 130  # Increased from 110 to make circles slightly bigger\n",
        "\n",
        "        # Calculate circle sizes based on maximum points\n",
        "        circle_sizes = {}\n",
        "        for i, max_p in enumerate(data['max_points']):\n",
        "            if max_p == 2:\n",
        "                circle_sizes[i] = base_size * 2  # 2 points get base size * 2\n",
        "            else:  # max_p == 3\n",
        "                circle_sizes[i] = base_size * 3  # 3 points get base size * 3\n",
        "\n",
        "        # Plot circles with size based on domain maximum points (consistent across columns)\n",
        "        for i, study_idx in enumerate(range(len(data['df_sorted']))):\n",
        "            for j, category_idx in enumerate(range(len(data['categories']))):\n",
        "                # Get the normalized value for color\n",
        "                normalized_value = data['sorted_normalized_matrix'][study_idx, category_idx]\n",
        "                # Get color from colormap\n",
        "                color = self.style.risk_cmap(normalized_value)\n",
        "\n",
        "                # Use pre-calculated size for this domain\n",
        "                circle_size = circle_sizes[category_idx]\n",
        "\n",
        "                # Create a circle using scatter plot\n",
        "                ax1.scatter(j, i, s=circle_size, c=[color], alpha=0.8,\n",
        "                          edgecolors='white', linewidths=0.5, zorder=2)\n",
        "\n",
        "        # Create y-axis labels (study names without risk level abbreviation)\n",
        "        y_labels = data['df_sorted']['Study'].values\n",
        "\n",
        "        # Set y-axis labels with increased font size\n",
        "        ax1.set_yticks(range(len(y_labels)))\n",
        "        ax1.set_yticklabels(y_labels, fontsize=8, rotation=0)\n",
        "        ax1.tick_params(axis='y', pad=25)\n",
        "\n",
        "        # Set x-axis labels horizontally with full category names\n",
        "        ax1.set_xticks(range(len(data['categories'])))\n",
        "\n",
        "        # Create x-labels - now vertical and on one line with proper point notation\n",
        "        x_labels = []\n",
        "        for cat, max_p in zip(data['categories'], data['max_points']):\n",
        "            # Simplified label format - single line, no breaks\n",
        "            if cat == \"Error Analysis\":\n",
        "                label = \"Error Analysis\"\n",
        "            elif cat == \"Fairness Assessment\":\n",
        "                label = \"Fairness Assessment\"\n",
        "            elif cat == \"Dataset Availability\":\n",
        "                label = \"Dataset Availability\"\n",
        "            elif cat == \"External Validation\":\n",
        "                label = \"External Validation\"\n",
        "            elif cat == \"Annotation Guidelines\":\n",
        "                label = \"Annotation Guidelines\"\n",
        "            elif cat == \"Code/Prompt Availability\":\n",
        "                label = \"Code/Prompt Availability\"\n",
        "            elif cat == \"Medical Condition Specificity\":\n",
        "                label = \"Medical Condition\"\n",
        "            else:\n",
        "                label = cat\n",
        "\n",
        "            # Add points notation\n",
        "            x_labels.append(f\"{label} ({max_p} pts)\")\n",
        "\n",
        "        # Set vertical x-axis labels with decreased font size\n",
        "        ax1.set_xticklabels(x_labels, rotation=90, ha='center', va='top', fontsize=8, fontweight='bold')\n",
        "        ax1.tick_params(axis='x', pad=7)\n",
        "        ax1.set_title('Domain Scores by Study', fontsize=9, fontweight='bold', pad=15)\n",
        "\n",
        "        # Set up the axes for the priority scores visualization with increased spacing\n",
        "        ax2.set_xlim(-0.5, 3-0.5)  # Now only 3 columns (High, Medium, Standard)\n",
        "        ax2.set_ylim(-0.5 - y_padding, num_studies-0.5 + y_padding)\n",
        "\n",
        "        # Add dotted light grid lines to priority scores visualization\n",
        "        ax2.set_axisbelow(True)\n",
        "        ax2.grid(which='both', linestyle=':', linewidth=0.5, color='#cccccc', alpha=0.7)\n",
        "\n",
        "        # Set up the axes for the total score visualization\n",
        "        ax3.set_xlim(-0.5, 0.5)  # Just one column\n",
        "        ax3.set_ylim(-0.5 - y_padding, num_studies-0.5 + y_padding)\n",
        "\n",
        "        # Add dotted light grid lines to total score visualization\n",
        "        ax3.set_axisbelow(True)\n",
        "        ax3.grid(which='both', linestyle=':', linewidth=0.5, color='#cccccc', alpha=0.7)\n",
        "\n",
        "        # Add shading to total score column\n",
        "        ax3.axvspan(-0.5, 0.5, color='#e6e6e6', alpha=0.7, zorder=0)\n",
        "\n",
        "        # For consistency - add same alternating row shading to both summary sections with increased height\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            if i % 2 == 0:  # Even rows\n",
        "                ax2.axhspan(i-0.5 - y_padding/2, i+0.5 + y_padding/2, color='#f5f5f5', alpha=0.3, zorder=0)\n",
        "                ax3.axhspan(i-0.5 - y_padding/2, i+0.5 + y_padding/2, color='#f5f5f5', alpha=0.3, zorder=0)\n",
        "\n",
        "        # Prepare data for summary visualizations\n",
        "        summary_data_priorities = np.zeros((len(data['df_sorted']), 3))\n",
        "        summary_data_priorities[:, 0] = data['df_sorted']['High Priority Score'].values / data['max_high_priority']\n",
        "        summary_data_priorities[:, 1] = data['df_sorted']['Medium Priority Score'].values / data['max_medium_priority']\n",
        "        summary_data_priorities[:, 2] = data['df_sorted']['Standard Priority Score'].values / data['max_standard_priority']\n",
        "\n",
        "        summary_data_total = np.zeros((len(data['df_sorted']), 1))\n",
        "        summary_data_total[:, 0] = data['df_sorted']['Total Score'].values / data['max_total']\n",
        "\n",
        "        # Use a larger size for all priority section circles\n",
        "        priority_circle_size = 290\n",
        "        total_circle_size = 310  # Slightly larger for total score\n",
        "\n",
        "        # Plot circles for priority scores\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            for j in range(3):  # 3 columns: High, Medium, Standard\n",
        "                normalized_value = summary_data_priorities[i, j]\n",
        "                color = self.style.risk_cmap(normalized_value)\n",
        "\n",
        "                # Create a circle using scatter plot\n",
        "                ax2.scatter(j, i, s=priority_circle_size, c=[color], alpha=0.8,\n",
        "                           edgecolors='white', linewidths=0.5, zorder=2)\n",
        "\n",
        "                # Add score text inside each circle\n",
        "                if j == 0:\n",
        "                    score = data['df_sorted']['High Priority Score'].iloc[i]\n",
        "                elif j == 1:\n",
        "                    score = data['df_sorted']['Medium Priority Score'].iloc[i]\n",
        "                else:  # j == 2\n",
        "                    score = data['df_sorted']['Standard Priority Score'].iloc[i]\n",
        "\n",
        "                ax2.text(j, i, str(int(score)), ha='center', va='center', fontsize=6,\n",
        "                        color='white', fontweight='bold', zorder=3)  # Text on top\n",
        "\n",
        "        # Plot circles for total score\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            normalized_value = summary_data_total[i, 0]\n",
        "            color = self.style.risk_cmap(normalized_value)\n",
        "\n",
        "            # Create a circle using scatter plot\n",
        "            ax3.scatter(0, i, s=total_circle_size, c=[color], alpha=0.8,\n",
        "                       edgecolors='white', linewidths=0.5, zorder=2)\n",
        "\n",
        "            # Add score text inside each circle\n",
        "            score = data['df_sorted']['Total Score'].iloc[i]\n",
        "            ax3.text(0, i, str(int(score)), ha='center', va='center', fontsize=6,\n",
        "                    color='white', fontweight='bold', zorder=3)  # Text on top\n",
        "\n",
        "        # Make priority scores x-axis labels vertical with decreased font\n",
        "        ax2.set_xticks(range(3))\n",
        "        ax2.set_xticklabels([\n",
        "            f'High Priority ({data[\"max_high_priority\"]})',\n",
        "            f'Medium Priority ({data[\"max_medium_priority\"]})',\n",
        "            f'Standard Priority ({data[\"max_standard_priority\"]})'\n",
        "        ], rotation=90, ha='center', va='top', fontsize=8, fontweight='bold')\n",
        "        ax2.tick_params(axis='x', pad=7)\n",
        "\n",
        "        # Set up total score x-axis label\n",
        "        ax3.set_xticks([0])\n",
        "        ax3.set_xticklabels([f'Total Score ({data[\"max_total\"]})'],\n",
        "                             rotation=90, ha='center', va='top', fontsize=8, fontweight='bold')\n",
        "        ax3.tick_params(axis='x', pad=7)\n",
        "\n",
        "        # Remove y-axis labels for summary sections\n",
        "        ax2.set_yticklabels(['' for _ in range(len(data['df_sorted']))])\n",
        "        ax3.set_yticklabels(['' for _ in range(len(data['df_sorted']))])\n",
        "\n",
        "        # Set titles for summary sections\n",
        "        ax2.set_title('Priority Scores', fontsize=9, fontweight='bold', pad=15)\n",
        "        ax3.set_title('Overall Score', fontsize=9, fontweight='bold', pad=15)\n",
        "\n",
        "        # Create legend for risk levels and circle sizes\n",
        "        from matplotlib.lines import Line2D\n",
        "        risk_legend_elements = [\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=self.style.color_palette['Low Risk'],\n",
        "                  markersize=12, label='Low Risk', markeredgecolor='white', markeredgewidth=0.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=self.style.color_palette['Medium Risk'],\n",
        "                  markersize=12, label='Medium Risk', markeredgecolor='white', markeredgewidth=0.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=self.style.color_palette['High Risk'],\n",
        "                  markersize=12, label='High Risk', markeredgecolor='white', markeredgewidth=0.5)\n",
        "        ]\n",
        "\n",
        "        # Create size legend only for the domain section\n",
        "        size_legend_elements = [\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor='#999999',\n",
        "                   markersize=np.sqrt(base_size * 2)/2.5, label='2 points',\n",
        "                   markeredgecolor='white', markeredgewidth=0.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor='#999999',\n",
        "                   markersize=np.sqrt(base_size * 3)/2.5, label='3 points',\n",
        "                   markeredgecolor='white', markeredgewidth=0.5)\n",
        "        ]\n",
        "\n",
        "        # Create the combined legend\n",
        "        all_legend_elements = risk_legend_elements + size_legend_elements\n",
        "        all_legend_labels = ['Low Risk', 'Medium Risk', 'High Risk', '2 points', '3 points']\n",
        "\n",
        "        # Add the combined legend with larger font\n",
        "        legend = legend_ax.legend(all_legend_elements, all_legend_labels,\n",
        "                               loc='center', fontsize=8, frameon=True,\n",
        "                               ncol=5, columnspacing=1.0,\n",
        "                               bbox_to_anchor=(0.5, 0.5))\n",
        "\n",
        "        # Move the title a bit closer to the plot\n",
        "        combined_fig.suptitle('Risk of Bias Assessment for LLMs Identifying SDoH',\n",
        "                             fontsize=12, fontweight='bold', y=0.92)\n",
        "\n",
        "        # Move criteria text a bit closer to the plot\n",
        "        criteria_text = \"\"\"Risk Criteria: Low: ≥14 total AND ≥6 High AND ≥3 Medium points | Medium: ≥9 total AND ≥4 High AND ≥2 Medium points | High: Below thresholds\"\"\"\n",
        "        combined_fig.text(0.5, 0.1, criteria_text, ha='center', fontsize=7,\n",
        "                        bbox={'facecolor': 'lightgrey', 'alpha': 0.5, 'pad': 5})\n",
        "\n",
        "        # Adjust layout to better accommodate all elements\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "\n",
        "        plt.savefig('risk_assessment_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('risk_assessment_heatmap.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_risk_distribution(self, data):\n",
        "        \"\"\"Creates bar chart of risk level distribution\"\"\"\n",
        "        # Count studies in each risk category\n",
        "        risk_counts = data['df']['Risk Level'].value_counts()\n",
        "\n",
        "        # Create a complete DataFrame with all risk levels\n",
        "        all_risk_levels = ['High Risk', 'Medium Risk', 'Low Risk']\n",
        "        complete_risk_counts = pd.Series(0, index=all_risk_levels)\n",
        "\n",
        "        # Update with actual counts\n",
        "        for level in risk_counts.index:\n",
        "            complete_risk_counts[level] = risk_counts[level]\n",
        "\n",
        "        # Sort in desired order\n",
        "        complete_risk_counts = complete_risk_counts.reindex(['High Risk', 'Medium Risk', 'Low Risk'])\n",
        "\n",
        "        plt.figure(figsize=(3.5, 2.5), facecolor=self.style.color_palette['background'])\n",
        "        bars = plt.bar(range(len(all_risk_levels)), complete_risk_counts.values,\n",
        "                       color=[self.style.color_palette[level] for level in all_risk_levels], width=0.6)\n",
        "\n",
        "        # Add count and percentage labels\n",
        "        for i, v in enumerate(complete_risk_counts.values):\n",
        "            if v > 0:\n",
        "                plt.text(i, v + 0.3, str(int(v)), ha='center', fontweight='bold', fontsize=7)\n",
        "                percentage = (v / len(data['studies'])) * 100\n",
        "                plt.text(i, v/2, f\"{percentage:.1f}%\", ha='center', va='center',\n",
        "                         color='white', fontweight='bold', fontsize=7)\n",
        "\n",
        "        plt.ylabel('Number of Studies', fontsize=8)\n",
        "        plt.title('Distribution of Studies by Risk Level', fontsize=9, fontweight='bold')\n",
        "        plt.ylim(0, max(complete_risk_counts.values) * 1.2 if max(complete_risk_counts.values) > 0 else 1)\n",
        "        plt.xticks(range(len(all_risk_levels)), ['High', 'Medium', 'Low'], fontsize=7)\n",
        "        plt.yticks(fontsize=7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('risk_level_distribution.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('risk_level_distribution.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_risk_by_year(self, data):\n",
        "        \"\"\"Creates stacked bar chart of risk levels by publication year\"\"\"\n",
        "        # Extract publication years from study names\n",
        "        years = []\n",
        "        for study in data['studies']:\n",
        "            year_part = study.split()[-1]\n",
        "            numeric_year = ''.join(c for c in year_part if c.isdigit())\n",
        "            years.append(int(numeric_year))\n",
        "\n",
        "        unique_years = sorted(set(years))\n",
        "\n",
        "        # Calculate risk level distribution by year\n",
        "        year_risk_data = {}\n",
        "        for year in unique_years:\n",
        "            year_indices = [i for i, y in enumerate(years) if y == year]\n",
        "            year_risk_levels = [data['df']['Risk Level'].iloc[i] for i in year_indices]\n",
        "            year_risk_counts = {'High Risk': 0, 'Medium Risk': 0, 'Low Risk': 0}\n",
        "            for risk in year_risk_levels:\n",
        "                year_risk_counts[risk] += 1\n",
        "            year_risk_data[year] = year_risk_counts\n",
        "\n",
        "        # Prepare data for stacked bar chart\n",
        "        years_for_plot = []\n",
        "        high_risk_counts = []\n",
        "        medium_risk_counts = []\n",
        "        low_risk_counts = []\n",
        "        study_counts = []\n",
        "\n",
        "        for year in unique_years:\n",
        "            years_for_plot.append(year)\n",
        "            high_risk_counts.append(year_risk_data[year]['High Risk'])\n",
        "            medium_risk_counts.append(year_risk_data[year]['Medium Risk'])\n",
        "            low_risk_counts.append(year_risk_data[year]['Low Risk'])\n",
        "            study_counts.append(sum(year_risk_data[year].values()))\n",
        "\n",
        "        # Create stacked bar chart\n",
        "        plt.figure(figsize=(4.5, 2.5), facecolor=self.style.color_palette['background'])\n",
        "        width = 0.6\n",
        "\n",
        "        p1 = plt.bar(years_for_plot, low_risk_counts, width, color=self.style.color_palette['Low Risk'], label='Low')\n",
        "        p2 = plt.bar(years_for_plot, medium_risk_counts, width,\n",
        "                     bottom=low_risk_counts, color=self.style.color_palette['Medium Risk'], label='Medium')\n",
        "        p3 = plt.bar(years_for_plot, high_risk_counts, width,\n",
        "                     bottom=[i+j for i,j in zip(low_risk_counts, medium_risk_counts)],\n",
        "                     color=self.style.color_palette['High Risk'], label='High')\n",
        "\n",
        "        # Add study count annotations\n",
        "        for i, count in enumerate(study_counts):\n",
        "            plt.text(years_for_plot[i], count + 0.2, f\"n={count}\", ha='center', fontsize=6)\n",
        "\n",
        "        plt.xlabel('Publication Year', fontsize=8)\n",
        "        plt.ylabel('Number of Studies', fontsize=8)\n",
        "        plt.title('Risk Levels by Publication Year', fontsize=9, fontweight='bold')\n",
        "        plt.xticks(years_for_plot, fontsize=7)\n",
        "        plt.yticks(fontsize=7)\n",
        "        plt.legend(fontsize=6, title=\"Risk\", title_fontsize=7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('risk_distribution_by_year.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('risk_distribution_by_year.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_domain_correlation(self, data):\n",
        "        \"\"\"Creates correlation heatmap between risk domains with complete, non-trimmed labels\"\"\"\n",
        "        # Normalize the scores for correlation calculation\n",
        "        normalized_scores = np.zeros_like(data['risk_matrix'], dtype=float)\n",
        "        for i, max_p in enumerate(data['max_points']):\n",
        "            normalized_scores[:, i] = data['risk_matrix'][:, i] / max_p\n",
        "\n",
        "        # Calculate correlation\n",
        "        corr_matrix = np.corrcoef(normalized_scores.T)\n",
        "        corr_df = pd.DataFrame(corr_matrix, index=data['categories'], columns=data['categories'])\n",
        "\n",
        "        # Create mask for lower triangle (including diagonal)\n",
        "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
        "\n",
        "        # Use the original full category names\n",
        "        category_labels = data['categories']\n",
        "\n",
        "        # Create a much larger figure to accommodate full-length labels\n",
        "        plt.figure(figsize=(11, 9), facecolor=self.style.color_palette['background'])\n",
        "\n",
        "        # Create custom color map\n",
        "        custom_cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "        # Create the heatmap with full original labels\n",
        "        heatmap = sns.heatmap(\n",
        "            corr_df,\n",
        "            annot=True,\n",
        "            cmap=custom_cmap,\n",
        "            vmin=-1,\n",
        "            vmax=1,\n",
        "            center=0,\n",
        "            linewidths=0.5,\n",
        "            fmt='.2f',\n",
        "            annot_kws={'size': 14},\n",
        "            mask=mask,\n",
        "            xticklabels=category_labels,\n",
        "            yticklabels=category_labels,\n",
        "            cbar_kws={'label': 'Correlation Coefficient'}\n",
        "        )\n",
        "\n",
        "        # Set x-axis labels with significant rotation and proper positioning\n",
        "        plt.xticks(rotation=45, ha='right', fontweight='bold', fontsize=12)\n",
        "\n",
        "        # Set y-axis labels\n",
        "        plt.yticks(rotation=0, va='center', fontweight='bold', fontsize=12)\n",
        "\n",
        "        # Adjust colorbar label\n",
        "        cbar = heatmap.collections[0].colorbar\n",
        "        cbar.ax.tick_params(labelsize=9)\n",
        "        cbar.set_label('Correlation Coefficient', fontsize=14)\n",
        "\n",
        "        # Add title with adjusted position\n",
        "        plt.title('Correlation Between Risk Domains', fontsize=14, fontweight='bold', pad=10)\n",
        "\n",
        "        # Add significant margins to ensure labels aren't cut off\n",
        "        plt.subplots_adjust(bottom=0.35, left=0.25)\n",
        "\n",
        "        # Save with extra padding to ensure no labels are trimmed\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('domain_correlation.png', dpi=300, bbox_inches='tight', pad_inches=0.5)\n",
        "        plt.savefig('domain_correlation.pdf', bbox_inches='tight', pad_inches=0.5)\n",
        "        plt.close()\n",
        "\n",
        "    def plot_score_scatter(self, data):\n",
        "        \"\"\"Creates scatter plot with larger points, elegant risk labels, and refined color schemes\n",
        "        with dynamic node positioning to avoid overlap and optimized connecting lines\"\"\"\n",
        "        # Import necessary modules\n",
        "        from matplotlib.lines import Line2D\n",
        "        import matplotlib.patheffects as path_effects\n",
        "        from scipy.spatial import distance\n",
        "        import numpy as np\n",
        "\n",
        "        # Extract and check data\n",
        "        df = data['df'].copy()  # Create a copy to avoid modifying the original\n",
        "\n",
        "        # Find overlapping points\n",
        "        coordinate_counts = df.groupby(['High Priority Score', 'Total Score']).size().reset_index(name='count')\n",
        "\n",
        "        # Create dictionary mapping coordinates to cluster size\n",
        "        cluster_sizes = {(row['High Priority Score'], row['Total Score']): row['count']\n",
        "                        for _, row in coordinate_counts.iterrows()}\n",
        "\n",
        "        # Print study count information\n",
        "        print(f\"Original dataset has {len(data['df'])} studies\")\n",
        "        print(f\"Number of unique (x,y) coordinates: {len(coordinate_counts)}\")\n",
        "\n",
        "        # Create larger figure with expanded axis limits\n",
        "        plt.figure(figsize=(12.0, 10.0), facecolor='white')\n",
        "\n",
        "        # Define distinct colors for each risk zone with more nuanced boundary colors\n",
        "        enhanced_colors = {\n",
        "            'Low Risk': '#1a9850',         # Green\n",
        "            'Medium Risk': '#fdae61',      # Orange/Yellow\n",
        "            'High Risk': '#d73027',        # Red\n",
        "            'Medium-High': '#f4a582',      # Lighter orange (boundary areas)\n",
        "            'High-Medium': '#d6604d',      # Lighter red (boundary areas)\n",
        "            'background': '#f8f9fa'        # Light gray background\n",
        "        }\n",
        "\n",
        "        # Expand the plot boundaries beyond the data range to create more space\n",
        "        x_min = -1.0\n",
        "        y_min = -1.0\n",
        "        x_max = data['max_high_priority'] + 1.0\n",
        "        y_max = data['max_total'] + 2.0\n",
        "\n",
        "        # Create smooth gradient background for risk zones\n",
        "        from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "        # Define custom colormaps for each risk zone\n",
        "        high_risk_cmap = LinearSegmentedColormap.from_list('high_risk', ['#ffebee', '#ffcdd2'])\n",
        "        medium_risk_cmap = LinearSegmentedColormap.from_list('medium_risk', ['#fff8e1', '#ffecb3'])\n",
        "        low_risk_cmap = LinearSegmentedColormap.from_list('low_risk', ['#e8f5e9', '#c8e6c9'])\n",
        "\n",
        "        # Create background with gradient shading across expanded area\n",
        "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                            np.linspace(y_min, y_max, 100))\n",
        "\n",
        "        # Define risk zones across expanded area\n",
        "        high_risk_mask = ((xx < 4) | ((xx < 6) & (yy < 9)))\n",
        "        medium_risk_mask = ((xx >= 4) & (xx < 6) & (yy >= 9) & (yy < 14)) | ((xx >= 6) & (yy < 14))\n",
        "        low_risk_mask = (xx >= 6) & (yy >= 14)\n",
        "\n",
        "        # Plot the risk zone backgrounds with slight transparency\n",
        "        plt.imshow(np.zeros_like(xx), extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0, aspect='auto')  # Create correct extent\n",
        "\n",
        "        plt.imshow(high_risk_mask, extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0.15, aspect='auto', cmap=high_risk_cmap, origin='lower')\n",
        "        plt.imshow(medium_risk_mask, extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0.15, aspect='auto', cmap=medium_risk_cmap, origin='lower')\n",
        "        plt.imshow(low_risk_mask, extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0.15, aspect='auto', cmap=low_risk_cmap, origin='lower')\n",
        "\n",
        "        # Add subtle grid lines\n",
        "        plt.grid(True, linestyle='-', linewidth=0.6, alpha=0.15, color='#bdbdbd')\n",
        "\n",
        "        # CORRECTED: Re-calculate risk levels based on criteria with detailed subcategories\n",
        "        df['Corrected Risk Level'] = 'High Risk'  # Default to high risk\n",
        "\n",
        "        # Medium risk: ≥9 total AND ≥4 High\n",
        "        medium_mask = (df['Total Score'] >= 9) & (df['High Priority Score'] >= 4)\n",
        "        df.loc[medium_mask, 'Corrected Risk Level'] = 'Medium Risk'\n",
        "\n",
        "        # Low risk: ≥14 total AND ≥6 High\n",
        "        low_mask = (df['Total Score'] >= 14) & (df['High Priority Score'] >= 6)\n",
        "        df.loc[low_mask, 'Corrected Risk Level'] = 'Low Risk'\n",
        "\n",
        "        # Add nuanced risk levels for boundary areas\n",
        "        # High-Medium: High priority is good (≥4) but total is below medium threshold (<9)\n",
        "        high_medium_mask = (df['High Priority Score'] >= 4) & (df['Total Score'] < 9)\n",
        "        df.loc[high_medium_mask, 'Corrected Risk Level'] = 'High-Medium'\n",
        "\n",
        "        # Medium-High: Total score is good (≥9) but high priority is below medium threshold (<4)\n",
        "        medium_high_mask = (df['Total Score'] >= 9) & (df['High Priority Score'] < 4)\n",
        "        df.loc[medium_high_mask, 'Corrected Risk Level'] = 'Medium-High'\n",
        "\n",
        "        # Plot each unique coordinate point\n",
        "        point_positions = []  # Store positions of all points\n",
        "        for _, row in coordinate_counts.iterrows():\n",
        "            x = row['High Priority Score']\n",
        "            y = row['Total Score']\n",
        "            count = row['count']\n",
        "\n",
        "            # Store point position\n",
        "            point_positions.append((x, y))\n",
        "\n",
        "            # Get representative risk level for this cluster (using first study at this position)\n",
        "            cluster_df = df[(df['High Priority Score'] == x) & (df['Total Score'] == y)]\n",
        "            risk_level = cluster_df['Corrected Risk Level'].iloc[0]\n",
        "            color = enhanced_colors[risk_level]\n",
        "\n",
        "            # Create scatter plot with LARGER points and clean styling\n",
        "            scatter = plt.scatter(x, y,\n",
        "                              c=[color],\n",
        "                              alpha=1.0, s=750,  # Large points\n",
        "                              edgecolors='black', linewidths=2.0,\n",
        "                              zorder=10)\n",
        "\n",
        "            # For points with multiple studies, add a count indicator\n",
        "            if count > 1:\n",
        "                plt.text(x, y, str(count), ha='center', va='center',\n",
        "                      color='white', fontsize=10, fontweight='bold', zorder=15)\n",
        "\n",
        "        # Create simplified labels\n",
        "        simple_labels = []\n",
        "        for study in df['Study']:\n",
        "            parts = study.split()\n",
        "            if len(parts) > 1:\n",
        "                name = parts[0]\n",
        "                year = parts[-1]\n",
        "                simple_labels.append(f\"{name} {year}\")\n",
        "            else:\n",
        "                simple_labels.append(study)\n",
        "\n",
        "        # Add simplified labels to dataframe\n",
        "        df['Simple_Label'] = simple_labels\n",
        "\n",
        "        # IMPROVED LABEL POSITIONING ALGORITHM WITH SHORTER STALKS\n",
        "\n",
        "        # Parameters for callout line style\n",
        "        callout_style = {'color': 'black', 'linewidth': 0.5, 'alpha': 0.7, 'zorder': 5}  # Thinner lines\n",
        "\n",
        "        # 1. Group studies by their coordinates\n",
        "        grouped_studies = df.groupby(['High Priority Score', 'Total Score'])\n",
        "\n",
        "        # Store all text objects and their associated lines\n",
        "        all_texts = []\n",
        "        all_lines = []\n",
        "        text_to_point = {}  # Map texts to their anchor points\n",
        "        label_bboxes = {}   # Store bounding boxes for label overlap detection\n",
        "\n",
        "        # 2. Improved dynamic label positioning function with SHORTER STALKS\n",
        "        def get_optimal_position(x, y, cluster_size, point_idx, total_points, other_points):\n",
        "            \"\"\"\n",
        "            Dynamically calculate optimal label position with shorter stalks based on:\n",
        "            - Point location in the chart\n",
        "            - Cluster size\n",
        "            - Index within cluster\n",
        "            - Positions of other points (to avoid overlap)\n",
        "            \"\"\"\n",
        "            # Base radius - SIGNIFICANTLY REDUCED for shorter stalks\n",
        "            base_radius = 0.45 + (0.05 * min(cluster_size - 1, 4))  # Much shorter stalks\n",
        "\n",
        "            # Special handling for regions with known overlap issues\n",
        "            if (x > 7 and y > 12) or (2 < x < 4 and 3 < y < 5) or (x == 3 and y == 5):\n",
        "                base_radius = 0.7  # Slightly longer stalks for problematic regions\n",
        "\n",
        "            if cluster_size == 1:\n",
        "                # For single points, position based on octants (8 directions)\n",
        "\n",
        "                # Determine octant (0-7) based on position in chart\n",
        "                chart_x_ratio = (x - x_min) / (x_max - x_min)  # 0 to 1\n",
        "                chart_y_ratio = (y - y_min) / (y_max - y_min)  # 0 to 1\n",
        "\n",
        "                # Choose direction based on position in chart - with shorter distances\n",
        "                if chart_x_ratio < 0.25:\n",
        "                    # Left quarter\n",
        "                    if chart_y_ratio < 0.25:\n",
        "                        dx, dy = 0.6, 0.2  # Bottom left - go right and slightly up\n",
        "                    elif chart_y_ratio < 0.5:\n",
        "                        dx, dy = 0.6, 0.0  # Middle-lower left - go right\n",
        "                    elif chart_y_ratio < 0.75:\n",
        "                        dx, dy = 0.6, 0.0  # Middle-upper left - go right\n",
        "                    else:\n",
        "                        dx, dy = 0.5, -0.3  # Top left - go right and down\n",
        "                elif chart_x_ratio < 0.5:\n",
        "                    # Middle-left quarter\n",
        "                    if chart_y_ratio < 0.25:\n",
        "                        dx, dy = 0.0, 0.6  # Bottom middle-left - go up\n",
        "                    elif chart_y_ratio < 0.5:\n",
        "                        dx, dy = 0.5, 0.4  # Middle-lower middle-left - go up-right\n",
        "                    elif chart_y_ratio < 0.75:\n",
        "                        dx, dy = 0.4, -0.4  # Middle-upper middle-left - go down-right\n",
        "                    else:\n",
        "                        dx, dy = 0.0, -0.6  # Top middle-left - go down\n",
        "                elif chart_x_ratio < 0.75:\n",
        "                    # Middle-right quarter\n",
        "                    if chart_y_ratio < 0.25:\n",
        "                        dx, dy = 0.0, 0.6  # Bottom middle-right - go up\n",
        "                    elif chart_y_ratio < 0.5:\n",
        "                        dx, dy = -0.5, 0.4  # Middle-lower middle-right - go up-left\n",
        "                    elif chart_y_ratio < 0.75:\n",
        "                        dx, dy = -0.4, -0.4  # Middle-upper middle-right - go down-left\n",
        "                    else:\n",
        "                        dx, dy = 0.0, -0.6  # Top middle-right - go down\n",
        "                else:\n",
        "                    # Right quarter\n",
        "                    if chart_y_ratio < 0.25:\n",
        "                        dx, dy = -0.5, 0.3  # Bottom right - go left and up\n",
        "                    elif chart_y_ratio < 0.5:\n",
        "                        dx, dy = -0.6, 0.0  # Middle-lower right - go left\n",
        "                    elif chart_y_ratio < 0.75:\n",
        "                        dx, dy = -0.6, 0.0  # Middle-upper right - go left\n",
        "                    else:\n",
        "                        dx, dy = -0.5, -0.3  # Top right - go left and down\n",
        "\n",
        "                # Scale by base_radius\n",
        "                dx *= base_radius\n",
        "                dy *= base_radius\n",
        "\n",
        "                # Set text alignment\n",
        "                ha = 'right' if dx < -0.1 else ('center' if abs(dx) <= 0.1 else 'left')\n",
        "                va = 'top' if dy < -0.1 else ('center' if abs(dy) <= 0.1 else 'bottom')\n",
        "\n",
        "                return dx, dy, ha, va\n",
        "            else:\n",
        "                # For clusters, arrange in a well-separated pattern using more directions\n",
        "\n",
        "                # Calculate how many items to place in each direction\n",
        "                # For large clusters, use 16 directions for better spacing\n",
        "                if cluster_size > 4 or (x == 3 and y == 5):  # Special handling for node at (3,5)\n",
        "                    directions = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE',\n",
        "                                'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\n",
        "                else:\n",
        "                    directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
        "\n",
        "                # Distribute items evenly across directions\n",
        "                items_per_direction = [total_points // len(directions) + (1 if i < total_points % len(directions) else 0)\n",
        "                                    for i in range(len(directions))]\n",
        "\n",
        "                # Find which direction this item belongs to\n",
        "                direction_idx = 0\n",
        "                count = 0\n",
        "                for i, num_items in enumerate(items_per_direction):\n",
        "                    count += num_items\n",
        "                    if point_idx < count:\n",
        "                        direction_idx = i\n",
        "                        break\n",
        "\n",
        "                # Calculate position based on direction\n",
        "                if len(directions) == 16:\n",
        "                    angles = {\n",
        "                        'N': np.pi/2, 'NNE': 5*np.pi/8, 'NE': 3*np.pi/4, 'ENE': 7*np.pi/8,\n",
        "                        'E': 0, 'ESE': -np.pi/8, 'SE': -np.pi/4, 'SSE': -3*np.pi/8,\n",
        "                        'S': -np.pi/2, 'SSW': -5*np.pi/8, 'SW': -3*np.pi/4, 'WSW': -7*np.pi/8,\n",
        "                        'W': np.pi, 'WNW': 7*np.pi/8, 'NW': 5*np.pi/4, 'NNW': 3*np.pi/8\n",
        "                    }\n",
        "                else:\n",
        "                    angles = {\n",
        "                        'N': np.pi/2, 'NE': np.pi/4, 'E': 0, 'SE': -np.pi/4,\n",
        "                        'S': -np.pi/2, 'SW': -3*np.pi/4, 'W': np.pi, 'NW': 3*np.pi/4\n",
        "                    }\n",
        "\n",
        "                angle = angles[directions[direction_idx]]\n",
        "\n",
        "                # Add slight variation within each direction\n",
        "                # Calculate which item this is within its direction\n",
        "                local_idx = point_idx - (count - items_per_direction[direction_idx])\n",
        "                max_local = items_per_direction[direction_idx]\n",
        "\n",
        "                if max_local > 1:\n",
        "                    spread = np.pi/(6 * len(directions))  # Smaller spread for more directions\n",
        "                    angle += spread * (2 * local_idx / (max_local - 1) - 1)\n",
        "\n",
        "                # Calculate position with SHORT stalks scaled by cluster size\n",
        "                if cluster_size >= 5:\n",
        "                    # For very large clusters, need a bit more space\n",
        "                    stalk_length = 0.6\n",
        "                else:\n",
        "                    stalk_length = 0.4 + 0.05 * cluster_size  # Much shorter baseline\n",
        "\n",
        "                dx = stalk_length * np.cos(angle)\n",
        "                dy = stalk_length * np.sin(angle)\n",
        "\n",
        "                # Set text alignment based on angle\n",
        "                ha = 'left' if -np.pi/2 < angle < np.pi/2 else 'right'\n",
        "                va = 'bottom' if 0 < angle < np.pi else 'top'\n",
        "\n",
        "                # Adjust for near-axis points\n",
        "                if abs(dx) < 0.1:\n",
        "                    ha = 'center'\n",
        "                if abs(dy) < 0.1:\n",
        "                    va = 'center'\n",
        "\n",
        "                return dx, dy, ha, va\n",
        "\n",
        "        # 3. Improved function to add text with better positioning\n",
        "        def add_optimized_callout(x, y, label, color, cluster_size, point_idx, total_points, other_points):\n",
        "            # Get optimal position\n",
        "            dx, dy, ha, va = get_optimal_position(x, y, cluster_size, point_idx, total_points, other_points)\n",
        "\n",
        "            # Create text with BLACK outline\n",
        "            text = plt.text(x + dx, y + dy, label,\n",
        "                          fontsize=7.5,  # Smaller font size for less overlap\n",
        "                          fontweight='bold',\n",
        "                          color=color, ha=ha, va=va, zorder=15,\n",
        "                          path_effects=[path_effects.withStroke(linewidth=0.1, foreground='black')])\n",
        "\n",
        "            # Add a simple straight line (no bezier curves) - shorter stalks are cleaner with straight lines\n",
        "            line = plt.plot([x, x + dx], [y, y + dy], **callout_style)[0]\n",
        "\n",
        "            # Store the relationship between text and its anchor point\n",
        "            text_to_point[text] = (x, y)\n",
        "\n",
        "            return text, line, (x + dx, y + dy)  # Return text position for overlap checking\n",
        "\n",
        "        # 4. First pass: position labels without considering overlaps\n",
        "        label_positions = {}  # Store label positions by (x,y) point\n",
        "\n",
        "        for (x, y), group in grouped_studies:\n",
        "            cluster_size = len(group)\n",
        "            label_positions[(x, y)] = []\n",
        "\n",
        "            # For each study in this cluster\n",
        "            for idx, (_, row) in enumerate(group.iterrows()):\n",
        "                label = row['Simple_Label']\n",
        "                color = enhanced_colors[row['Corrected Risk Level']]\n",
        "\n",
        "                # Add optimized positioned text and line\n",
        "                text, line, pos = add_optimized_callout(x, y, label, color, cluster_size, idx, cluster_size, point_positions)\n",
        "                all_texts.append(text)\n",
        "                all_lines.append(line)\n",
        "                label_positions[(x, y)].append(pos)  # Store position for this label\n",
        "\n",
        "        # 5. Get bounding boxes for all text objects\n",
        "        from matplotlib.transforms import Bbox\n",
        "\n",
        "        def get_text_bbox(text):\n",
        "            \"\"\"Get the bounding box of a text object in data coordinates\"\"\"\n",
        "            renderer = plt.gcf().canvas.get_renderer()\n",
        "            bbox = text.get_window_extent(renderer)\n",
        "            # Add padding to bounding box for better spacing\n",
        "            bbox = bbox.expanded(1.2, 1.2)  # 20% padding - more aggressive\n",
        "            bbox_data = bbox.transformed(plt.gca().transData.inverted())\n",
        "            return bbox_data\n",
        "\n",
        "        # 6. Improved overlap resolution with many iterations and more aggressive separation\n",
        "        for iteration in range(7):  # More iterations for better results\n",
        "            overlaps_resolved = 0\n",
        "\n",
        "            for i, text1 in enumerate(all_texts):\n",
        "                bbox1 = get_text_bbox(text1)\n",
        "                text1_pos = text1.get_position()\n",
        "\n",
        "                # Get the anchor point for this text\n",
        "                anchor_x, anchor_y = text_to_point[text1]\n",
        "\n",
        "                # Check for overlaps with other texts\n",
        "                for j, text2 in enumerate(all_texts):\n",
        "                    if i != j:  # Don't compare with self\n",
        "                        bbox2 = get_text_bbox(text2)\n",
        "\n",
        "                        # Check if bounding boxes overlap\n",
        "                        if bbox1.overlaps(bbox2):\n",
        "                            overlaps_resolved += 1\n",
        "\n",
        "                            # Get the anchor point for text2\n",
        "                            anchor2_x, anchor2_y = text_to_point[text2]\n",
        "\n",
        "                            # Calculate vector from text2 to text1\n",
        "                            vec = np.array([text1_pos[0] - text2.get_position()[0],\n",
        "                                          text1_pos[1] - text2.get_position()[1]])\n",
        "\n",
        "                            # If vector is very small, choose a random direction\n",
        "                            if np.linalg.norm(vec) < 0.01:\n",
        "                                angle = np.random.uniform(0, 2*np.pi)\n",
        "                                vec = np.array([np.cos(angle), np.sin(angle)])\n",
        "                            else:\n",
        "                                vec = vec / np.linalg.norm(vec)  # Normalize\n",
        "\n",
        "                            # Move text1 away from overlap - MORE AGGRESSIVE SEPARATION\n",
        "                            offset = 0.4  # Larger offset for more aggressive separation\n",
        "                            new_pos = (text1_pos[0] + offset * vec[0],\n",
        "                                      text1_pos[1] + offset * vec[1])\n",
        "\n",
        "                            # Make sure new position isn't too far from original point\n",
        "                            current_dist = np.sqrt((new_pos[0] - anchor_x)**2 + (new_pos[1] - anchor_y)**2)\n",
        "                            max_dist = 1.5  # Maximum allowed distance - REDUCED\n",
        "                            if current_dist > max_dist:\n",
        "                                scale_factor = max_dist / current_dist\n",
        "                                new_pos = (anchor_x + (new_pos[0] - anchor_x) * scale_factor,\n",
        "                                        anchor_y + (new_pos[1] - anchor_y) * scale_factor)\n",
        "\n",
        "                            text1.set_position(new_pos)\n",
        "\n",
        "                            # Update straight line\n",
        "                            all_lines[i].set_data([anchor_x, new_pos[0]], [anchor_y, new_pos[1]])\n",
        "\n",
        "                            # Update bbox1 after moving\n",
        "                            bbox1 = get_text_bbox(text1)\n",
        "\n",
        "                # Also check for overlap with points (not just other labels)\n",
        "                for px, py in point_positions:\n",
        "                    # Create a small bbox around the point\n",
        "                    point_bbox = Bbox.from_extents(px-0.25, py-0.25, px+0.25, py+0.25)\n",
        "\n",
        "                    if bbox1.overlaps(point_bbox) and (px, py) != (anchor_x, anchor_y):\n",
        "                        # Move text away from the point\n",
        "                        vec = np.array([text1_pos[0] - px, text1_pos[1] - py])\n",
        "                        if np.linalg.norm(vec) > 0:\n",
        "                            vec = vec / np.linalg.norm(vec)\n",
        "                        else:\n",
        "                            angle = np.random.uniform(0, 2*np.pi)\n",
        "                            vec = np.array([np.cos(angle), np.sin(angle)])\n",
        "\n",
        "                        offset = 0.35\n",
        "                        new_pos = (text1_pos[0] + offset * vec[0],\n",
        "                                  text1_pos[1] + offset * vec[1])\n",
        "\n",
        "                        # Limit how far we can move\n",
        "                        current_dist = np.sqrt((new_pos[0] - anchor_x)**2 + (new_pos[1] - anchor_y)**2)\n",
        "                        max_dist = 1.5  # REDUCED max distance\n",
        "                        if current_dist > max_dist:\n",
        "                            scale_factor = max_dist / current_dist\n",
        "                            new_pos = (anchor_x + (new_pos[0] - anchor_x) * scale_factor,\n",
        "                                    anchor_y + (new_pos[1] - anchor_y) * scale_factor)\n",
        "\n",
        "                        text1.set_position(new_pos)\n",
        "\n",
        "                        # Update the straight line\n",
        "                        all_lines[i].set_data([anchor_x, new_pos[0]], [anchor_y, new_pos[1]])\n",
        "\n",
        "                        # Update bbox1\n",
        "                        bbox1 = get_text_bbox(text1)\n",
        "\n",
        "            # If very few overlaps were resolved in this iteration, we can stop\n",
        "            if overlaps_resolved < 3:\n",
        "                break\n",
        "\n",
        "        # 7. Final check: find and fix any remaining overlaps with more aggressive moves\n",
        "        # This is a final, brute-force pass to eliminate any stubborn overlaps\n",
        "        for i, text1 in enumerate(all_texts):\n",
        "            bbox1 = get_text_bbox(text1)\n",
        "            text1_pos = text1.get_position()\n",
        "            anchor_x, anchor_y = text_to_point[text1]\n",
        "\n",
        "            for j, text2 in enumerate(all_texts):\n",
        "                if i != j:\n",
        "                    bbox2 = get_text_bbox(text2)\n",
        "\n",
        "                    if bbox1.overlaps(bbox2):\n",
        "                        # Calculate vector from text2 to text1\n",
        "                        vec = np.array([text1_pos[0] - text2.get_position()[0],\n",
        "                                      text1_pos[1] - text2.get_position()[1]])\n",
        "\n",
        "                        # If too close, pick a random direction\n",
        "                        if np.linalg.norm(vec) < 0.01:\n",
        "                            angle = np.random.uniform(0, 2*np.pi)\n",
        "                            vec = np.array([np.cos(angle), np.sin(angle)])\n",
        "                        else:\n",
        "                            vec = vec / np.linalg.norm(vec)\n",
        "\n",
        "                        # VERY aggressive separation\n",
        "                        offset = 0.5\n",
        "                        new_pos = (text1_pos[0] + offset * vec[0],\n",
        "                                  text1_pos[1] + offset * vec[1])\n",
        "\n",
        "                        text1.set_position(new_pos)\n",
        "                        all_lines[i].set_data([anchor_x, new_pos[0]], [anchor_y, new_pos[1]])\n",
        "                        bbox1 = get_text_bbox(text1)\n",
        "\n",
        "        # 8. Final pass to ensure no labels are outside plot boundaries\n",
        "        for i, text in enumerate(all_texts):\n",
        "            pos = text.get_position()\n",
        "            anchor_x, anchor_y = text_to_point[text]\n",
        "\n",
        "            # Check if text is outside boundaries and move it inside\n",
        "            # Add some padding to the boundaries\n",
        "            padding = 0.3\n",
        "            moved = False\n",
        "            new_pos = list(pos)\n",
        "\n",
        "            if pos[0] < x_min + padding:\n",
        "                new_pos[0] = x_min + padding\n",
        "                moved = True\n",
        "            elif pos[0] > x_max - padding:\n",
        "                new_pos[0] = x_max - padding\n",
        "                moved = True\n",
        "\n",
        "            if pos[1] < y_min + padding:\n",
        "                new_pos[1] = y_min + padding\n",
        "                moved = True\n",
        "            elif pos[1] > y_max - padding:\n",
        "                new_pos[1] = y_max - padding\n",
        "                moved = True\n",
        "\n",
        "            if moved:\n",
        "                text.set_position(new_pos)\n",
        "                all_lines[i].set_data([anchor_x, new_pos[0]], [anchor_y, new_pos[1]])\n",
        "\n",
        "        # Add threshold lines with elegant styling\n",
        "        plt.axhline(y=14, color=enhanced_colors['Low Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "        plt.axhline(y=9, color=enhanced_colors['Medium Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "        plt.axvline(x=6, color=enhanced_colors['Low Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "        plt.axvline(x=4, color=enhanced_colors['Medium Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "\n",
        "        # Add risk region labels with subtle effects\n",
        "        text_effects = [\n",
        "            path_effects.Stroke(linewidth=3, foreground='white', alpha=0.8),\n",
        "            path_effects.Normal()\n",
        "        ]\n",
        "\n",
        "        # Low Risk - positioned in the upper right corner\n",
        "        low_text = plt.text(9.2, 18, \"Low Risk\",\n",
        "                          fontsize=28,\n",
        "                          ha='center', va='center',\n",
        "                          color=enhanced_colors['Low Risk'],\n",
        "                          fontweight='bold', alpha=0.6,\n",
        "                          path_effects=text_effects,\n",
        "                          zorder=5)\n",
        "\n",
        "        # Medium Risk - positioned to avoid data points\n",
        "        med_text = plt.text(8.2, 12.5, \"Medium Risk\",\n",
        "                          fontsize=28,\n",
        "                          ha='center', va='center',\n",
        "                          color=enhanced_colors['Medium Risk'],\n",
        "                          fontweight='bold', alpha=0.6,\n",
        "                          path_effects=text_effects,\n",
        "                          zorder=5)\n",
        "\n",
        "        # High Risk - positioned in the bottom left corner\n",
        "        high_text = plt.text(0.5, 1.5, \"High Risk\",\n",
        "                            fontsize=28,\n",
        "                            ha='center', va='center',\n",
        "                            color=enhanced_colors['High Risk'],\n",
        "                            fontweight='bold', alpha=0.6,\n",
        "                            path_effects=text_effects,\n",
        "                            zorder=5)\n",
        "\n",
        "        # Add legends with elegant styling\n",
        "        legend_elements = [\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['Low Risk'],\n",
        "                  markersize=12, label='Low Risk', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['Medium Risk'],\n",
        "                  markersize=12, label='Medium Risk', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['High Risk'],\n",
        "                  markersize=12, label='High Risk', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            # Add boundary region colors to the legend\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['Medium-High'],\n",
        "                  markersize=12, label='Medium-High', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['High-Medium'],\n",
        "                  markersize=12, label='High-Medium', markeredgecolor='black', markeredgewidth=1.5),\n",
        "        ]\n",
        "\n",
        "        # Legend for risk levels with improved styling\n",
        "        legend = plt.legend(handles=legend_elements, loc='upper left', fontsize=10,\n",
        "                          title='Risk Level', title_fontsize=11,\n",
        "                          framealpha=0.9, edgecolor='#d4d4d4')\n",
        "\n",
        "        # Style the plot borders and ticks\n",
        "        ax = plt.gca()\n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_visible(True)\n",
        "            spine.set_color('#d4d4d4')\n",
        "            spine.set_linewidth(0.8)\n",
        "\n",
        "        # Add more elegant tick styling\n",
        "        ax.tick_params(axis='both', which='major', labelsize=10, colors='#505050', length=5, width=0.8)\n",
        "\n",
        "        # Add an elegant title\n",
        "        plt.title('Relationship Between High Priority Score and Total Score',\n",
        "                fontsize=16, fontweight='bold', color='#202020', pad=15)\n",
        "\n",
        "        # Make x and y labels more informative\n",
        "        plt.xlabel('High Priority Score (max 9)', fontsize=12, fontweight='bold', color='#303030')\n",
        "        plt.ylabel('Total Score (max 18)', fontsize=12, fontweight='bold', color='#303030')\n",
        "\n",
        "        # Set expanded axis limits to create more space\n",
        "        plt.xlim(x_min, x_max)\n",
        "        plt.ylim(y_min, y_max)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Add a note about threshold criteria with elegant styling\n",
        "        plt.subplots_adjust(bottom=0.12)  # Create more space at bottom\n",
        "\n",
        "        threshold_note = \"Risk Criteria: Low: ≥14 total AND ≥6 High | Medium: ≥9 total AND ≥4 High | High: Below thresholds\"\n",
        "        plt.figtext(0.5, 0.02, threshold_note, ha='center', fontsize=9, color='#505050',\n",
        "                  bbox=dict(facecolor='#f5f5f5', edgecolor='#d4d4d4', linewidth=0.5,\n",
        "                          alpha=0.95, boxstyle='round,pad=0.4,rounding_size=0.2'))\n",
        "\n",
        "        plt.savefig('high_priority_vs_total_score.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('high_priority_vs_total_score.svg', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "#########################################\n",
        "# MAIN FUNCTION\n",
        "#########################################\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the analysis and generate all visualizations\"\"\"\n",
        "    # Initialize style settings\n",
        "    style = PlotStyle()\n",
        "\n",
        "    # Define study data (can be loaded from external source)\n",
        "    study_data = {\n",
        "        'studies': [\n",
        "            \"Patra 2025\", \"Kim 2025\", \"Scherbakov 2025\", \"Rabbani 2024\", \"Shah-Mohammadi 2024a\",\n",
        "            \"Gu 2024\", \"Shah-Mohammadi 2024b\", \"Huang 2024\", \"Roosan 2024a\", \"Fu 2024\",\n",
        "            \"Guevara 2024\", \"Madrid-García 2024\", \"Yu 2024\", \"Peng 2024\", \"Sushil 2024\",\n",
        "            \"Keloth 2024\", \"Kwon 2024\", \"Holmes 2024\", \"Roosan 2024b\", \"Petit-Jean 2024\",\n",
        "            \"Roy 2024\", \"Gabriel 2024\", \"Robitschek 2024\", \"Ralevski 2024\", \"Yao 2023\",\n",
        "            \"Ramachandran 2023\", \"Turchin 2023\", \"Wang 2023\", \"Richie 2023\", \"Bhate 2023\",\n",
        "            \"Kim 2023\", \"Lituiev 2022\", \"Kugic 2022\", \"Botelle 2022\", \"Han 2022\"\n",
        "        ],\n",
        "        'categories': [\n",
        "            \"Error Analysis\", \"Fairness Assessment\", \"Annotation Guidelines\",\n",
        "            \"External Validation\", \"Medical Condition Specificity\",\n",
        "            \"Code/Prompt Availability\", \"Dataset Availability\"\n",
        "        ],\n",
        "        'priority_levels': [\n",
        "            \"High\", \"High\", \"High\",\n",
        "            \"Medium\", \"Medium\",\n",
        "            \"Standard\", \"Standard\"\n",
        "        ],\n",
        "        'max_points': [3, 3, 3, 3, 2, 2, 2],\n",
        "        'scores': {\n",
        "            \"Error Analysis\": [3 if x == 1 else 0 for x in [1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]],\n",
        "            \"Fairness Assessment\": [3 if x == 1 else 0 for x in [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
        "            \"Annotation Guidelines\": [3 if x == 1 else 0 for x in [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]],\n",
        "            \"External Validation\": [3 if x == 1 else 0 for x in [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
        "            \"Medical Condition Specificity\": [2 if x == 1 else 0 for x in [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]],\n",
        "            \"Code/Prompt Availability\": [2 if x == 1 else 0 for x in [1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
        "            \"Dataset Availability\": [2 if x == 1 else 0 for x in [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Prepare data\n",
        "    processor = DataProcessor(study_data)\n",
        "    processed_data = processor.processed_data\n",
        "\n",
        "    # Initialize visualizer\n",
        "    visualizer = Visualizer(style)\n",
        "\n",
        "    # Generate all visualizations\n",
        "    visualizer.plot_domain_completion(processed_data)\n",
        "    visualizer.plot_risk_assessment_heatmap(processed_data)\n",
        "    visualizer.plot_risk_distribution(processed_data)\n",
        "    visualizer.plot_risk_by_year(processed_data)\n",
        "    visualizer.plot_domain_correlation(processed_data)\n",
        "    visualizer.plot_score_scatter(processed_data)\n",
        "\n",
        "    print(\"All visualizations have been generated successfully.\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "# Install adjustText if not available\n",
        "try:\n",
        "    from adjustText import adjust_text\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"adjustText\"])\n",
        "    from adjustText import adjust_text\n",
        "\n",
        "#########################################\n",
        "# CONFIGURATION AND STYLING\n",
        "#########################################\n",
        "\n",
        "class PlotStyle:\n",
        "    \"\"\"Class to manage plot styling and color palettes\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.color_palette = {\n",
        "            'High Risk': '#e41a1c',     # Bright red (Nature standard)\n",
        "            'Medium Risk': '#ff9900',   # Orange (Nature standard)\n",
        "            'Low Risk': '#4daf4a',      # Green (Nature standard)\n",
        "            'primary_blue': '#377eb8',  # Nature standard blue\n",
        "            'secondary_blue': '#80b1d3', # Lighter blue\n",
        "            'light_blue': '#deebf7',    # Very light blue\n",
        "            'background': '#ffffff',    # White background\n",
        "            'grid': '#e6e6e6',          # Light gray grid\n",
        "            'text': '#3c3c3c',          # Dark gray text\n",
        "            'accent1': '#984ea3',       # Purple (Nature standard)\n",
        "            'accent2': '#a65628',       # Brown (Nature standard)\n",
        "            'accent3': '#f781bf'        # Pink (Nature standard)\n",
        "        }\n",
        "\n",
        "        self.risk_cmap = self._create_risk_colormap()\n",
        "        self._set_plot_parameters()\n",
        "\n",
        "    def _create_risk_colormap(self):\n",
        "        \"\"\"Create colormap from red to yellow to green for heatmaps\"\"\"\n",
        "        return LinearSegmentedColormap.from_list(\n",
        "            'risk_cmap',\n",
        "            [(0.0, self.color_palette['High Risk']),\n",
        "             (0.5, self.color_palette['Medium Risk']),\n",
        "             (1.0, self.color_palette['Low Risk'])],\n",
        "            N=100\n",
        "        )\n",
        "\n",
        "    def _set_plot_parameters(self):\n",
        "        \"\"\"Set global matplotlib parameters for Nature style\"\"\"\n",
        "        plt.rcParams.update({\n",
        "            'axes.titlesize': 9,\n",
        "            'axes.titleweight': 'bold',\n",
        "            'axes.labelsize': 8,\n",
        "            'xtick.labelsize': 7,\n",
        "            'ytick.labelsize': 7,\n",
        "            'legend.fontsize': 7,\n",
        "            'figure.facecolor': self.color_palette['background'],\n",
        "            'axes.facecolor': self.color_palette['background'],\n",
        "            'figure.figsize': (3.5, 2.5),\n",
        "            'axes.grid': False,\n",
        "            'grid.color': self.color_palette['grid'],\n",
        "            'grid.alpha': 0.5,\n",
        "            'axes.linewidth': 0.5,\n",
        "            'xtick.major.width': 0.5,\n",
        "            'ytick.major.width': 0.5,\n",
        "            'lines.linewidth': 1.0,\n",
        "            'lines.markersize': 3,\n",
        "            'savefig.dpi': 300,\n",
        "            'savefig.format': 'pdf',\n",
        "            'savefig.bbox': 'tight',\n",
        "            'savefig.transparent': False\n",
        "        })\n",
        "\n",
        "#########################################\n",
        "# DATA PREPARATION\n",
        "#########################################\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Class to process and prepare data for visualization\"\"\"\n",
        "\n",
        "    def __init__(self, study_data):\n",
        "        \"\"\"\n",
        "        Initialize with study data dictionary containing:\n",
        "        - studies: List of study names\n",
        "        - categories: List of assessment categories\n",
        "        - priority_levels: List of priority levels for each category\n",
        "        - max_points: List of maximum points for each category\n",
        "        - scores: Dictionary of scores for each category\n",
        "        \"\"\"\n",
        "        self.study_data = study_data\n",
        "        self.processed_data = self._process_data()\n",
        "\n",
        "    def _process_data(self):\n",
        "        \"\"\"Process the raw data into a structured format\"\"\"\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(self.study_data['scores'])\n",
        "        df['Study'] = self.study_data['studies']\n",
        "\n",
        "        # Extract risk matrix\n",
        "        risk_matrix = np.array(df[self.study_data['categories']])\n",
        "\n",
        "        # Group categories by priority level\n",
        "        high_priority_indices = [i for i, level in enumerate(self.study_data['priority_levels']) if level == \"High\"]\n",
        "        medium_priority_indices = [i for i, level in enumerate(self.study_data['priority_levels']) if level == \"Medium\"]\n",
        "        standard_priority_indices = [i for i, level in enumerate(self.study_data['priority_levels']) if level == \"Standard\"]\n",
        "\n",
        "        # Calculate scores\n",
        "        high_priority_scores = risk_matrix[:, high_priority_indices].sum(axis=1)\n",
        "        medium_priority_scores = risk_matrix[:, medium_priority_indices].sum(axis=1)\n",
        "        standard_priority_scores = risk_matrix[:, standard_priority_indices].sum(axis=1)\n",
        "        total_scores = risk_matrix.sum(axis=1)\n",
        "\n",
        "        # Determine risk levels based on framework criteria\n",
        "        risk_levels = []\n",
        "        for i in range(len(self.study_data['studies'])):\n",
        "            if (total_scores[i] >= 14 and high_priority_scores[i] >= 6 and medium_priority_scores[i] >= 3):\n",
        "                risk_levels.append(\"Low Risk\")\n",
        "            elif (total_scores[i] >= 9 and high_priority_scores[i] >= 4 and medium_priority_scores[i] >= 2):\n",
        "                risk_levels.append(\"Medium Risk\")\n",
        "            else:\n",
        "                risk_levels.append(\"High Risk\")\n",
        "\n",
        "        # Add calculated values to DataFrame\n",
        "        df[\"High Priority Score\"] = high_priority_scores\n",
        "        df[\"Medium Priority Score\"] = medium_priority_scores\n",
        "        df[\"Standard Priority Score\"] = standard_priority_scores\n",
        "        df[\"Total Score\"] = total_scores\n",
        "        df[\"Risk Level\"] = risk_levels\n",
        "\n",
        "        # Calculate maximum possible scores\n",
        "        max_high_priority = sum([self.study_data['max_points'][i] for i in high_priority_indices])\n",
        "        max_medium_priority = sum([self.study_data['max_points'][i] for i in medium_priority_indices])\n",
        "        max_standard_priority = sum([self.study_data['max_points'][i] for i in standard_priority_indices])\n",
        "        max_total = sum(self.study_data['max_points'])\n",
        "\n",
        "        # Create normalized matrix for visualization\n",
        "        normalized_matrix = np.zeros((len(df), len(self.study_data['categories'])))\n",
        "        for i, cat in enumerate(self.study_data['categories']):\n",
        "            normalized_matrix[:, i] = df[cat].values / self.study_data['max_points'][i]\n",
        "\n",
        "        # Sort studies by total score\n",
        "        df_sorted = df.sort_values(by=\"Total Score\", ascending=False)\n",
        "\n",
        "        # Create normalized matrix for sorted data\n",
        "        sorted_normalized_matrix = np.zeros((len(df_sorted), len(self.study_data['categories'])))\n",
        "        for i, cat in enumerate(self.study_data['categories']):\n",
        "            sorted_normalized_matrix[:, i] = df_sorted[cat].values / self.study_data['max_points'][i]\n",
        "\n",
        "        return {\n",
        "            'df': df,\n",
        "            'df_sorted': df_sorted,\n",
        "            'risk_matrix': risk_matrix,\n",
        "            'normalized_matrix': normalized_matrix,\n",
        "            'sorted_normalized_matrix': sorted_normalized_matrix,\n",
        "            'categories': self.study_data['categories'],\n",
        "            'studies': self.study_data['studies'],\n",
        "            'priority_levels': self.study_data['priority_levels'],\n",
        "            'max_points': self.study_data['max_points'],\n",
        "            'high_priority_indices': high_priority_indices,\n",
        "            'medium_priority_indices': medium_priority_indices,\n",
        "            'standard_priority_indices': standard_priority_indices,\n",
        "            'max_high_priority': max_high_priority,\n",
        "            'max_medium_priority': max_medium_priority,\n",
        "            'max_standard_priority': max_standard_priority,\n",
        "            'max_total': max_total\n",
        "        }\n",
        "\n",
        "#########################################\n",
        "# VISUALIZATION FUNCTIONS\n",
        "#########################################\n",
        "\n",
        "class Visualizer:\n",
        "    \"\"\"Class containing all visualization functions\"\"\"\n",
        "\n",
        "    def __init__(self, style):\n",
        "        self.style = style\n",
        "\n",
        "    def plot_domain_completion(self, data):\n",
        "        \"\"\"Creates stacked bar chart of domain completion rates\"\"\"\n",
        "        plt.figure(figsize=(6.5, 3.5), facecolor=self.style.color_palette['background'])\n",
        "\n",
        "        # Calculate completion percentage for each domain\n",
        "        completion_percent = []\n",
        "        for i, cat in enumerate(data['categories']):\n",
        "            total_points = data['df'][cat].sum()\n",
        "            max_possible_points = data['max_points'][i] * len(data['studies'])\n",
        "            percent = (total_points / max_possible_points) * 100\n",
        "            completion_percent.append(percent)\n",
        "\n",
        "        # Create DataFrame for stacked bar\n",
        "        df_stacked = pd.DataFrame({\n",
        "            'Domain': data['categories'],\n",
        "            'Completion (%)': completion_percent,\n",
        "            'Missing (%)': [100 - p for p in completion_percent],\n",
        "            'Priority': data['priority_levels'],\n",
        "            'Max Points': data['max_points']\n",
        "        })\n",
        "\n",
        "        # Sort by priority level and completion percentage\n",
        "        priority_order = {\"High\": 0, \"Medium\": 1, \"Standard\": 2}\n",
        "        df_stacked['Priority Order'] = df_stacked['Priority'].map(priority_order)\n",
        "        df_stacked = df_stacked.sort_values(['Priority Order', 'Completion (%)'], ascending=[True, False])\n",
        "\n",
        "        # Create stacked bars\n",
        "        plt.barh(df_stacked['Domain'], df_stacked['Completion (%)'],\n",
        "            color=self.style.color_palette['Low Risk'], label='Complete', alpha=0.8, height=0.6)\n",
        "        plt.barh(df_stacked['Domain'], df_stacked['Missing (%)'],\n",
        "            left=df_stacked['Completion (%)'], color=self.style.color_palette['High Risk'],\n",
        "            label='Missing', alpha=0.8, height=0.6)\n",
        "\n",
        "        # Add annotations\n",
        "        for i, (domain, priority, points) in enumerate(zip(df_stacked['Domain'], df_stacked['Priority'], df_stacked['Max Points'])):\n",
        "            plt.text(101, i, f'{priority} ({points}pts)', va='center', fontsize=6)\n",
        "\n",
        "        # Add separator lines between priority groups\n",
        "        priority_groups = df_stacked.groupby('Priority Order')\n",
        "        cumulative_count = 0\n",
        "        for name, group in priority_groups:\n",
        "            if name > 0:  # Don't add a line before the first group\n",
        "                plt.axhline(y=cumulative_count - 0.5, color='black', linestyle='-', alpha=0.3, linewidth=0.5)\n",
        "            cumulative_count += len(group)\n",
        "\n",
        "        # Finalize plot\n",
        "        plt.xlim(0, 120)\n",
        "        plt.xlabel('Percentage of Maximum Possible Points (%)', fontsize=8)\n",
        "        plt.title('Domain Completion Rate by Priority Level', fontsize=9, fontweight='bold')\n",
        "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, fontsize=7)\n",
        "        plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('domain_completion_by_priority.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('domain_completion_by_priority.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_risk_assessment_heatmap(self, data):\n",
        "        \"\"\"Creates traffic light visualization with circles sized by domain max points\"\"\"\n",
        "        # Adjust figure dimensions - narrower width, taller height\n",
        "        combined_fig = plt.figure(figsize=(5, 17), facecolor=self.style.color_palette['background'])\n",
        "\n",
        "        # Update grid proportions with more height\n",
        "        grid = plt.GridSpec(2, 21, height_ratios=[20, 1], hspace=0.4)\n",
        "\n",
        "        # Create subplots with adjusted widths\n",
        "        ax1 = combined_fig.add_subplot(grid[0, :11])  # Main visualization\n",
        "        ax2 = combined_fig.add_subplot(grid[0, 12:17])  # Priority scores\n",
        "        ax3 = combined_fig.add_subplot(grid[0, 19:])  # Total score column\n",
        "        legend_ax = combined_fig.add_subplot(grid[1, :])  # Legend at bottom\n",
        "        legend_ax.axis('off')  # Hide axis for legend\n",
        "\n",
        "        # Significantly increase the y-axis limits to create more space between rows\n",
        "        num_studies = len(data['df_sorted'])\n",
        "        y_padding = 0.8  # Greatly increased padding between rows\n",
        "\n",
        "        # Set up the axes with increased spacing\n",
        "        ax1.set_xlim(-0.5, len(data['categories'])-0.5)\n",
        "        ax1.set_ylim(-0.5 - y_padding, num_studies-0.5 + y_padding)\n",
        "\n",
        "        # Add dotted light grid lines to main visualization\n",
        "        ax1.set_axisbelow(True)\n",
        "        ax1.grid(which='both', linestyle=':', linewidth=0.5, color='#cccccc', alpha=0.7)\n",
        "\n",
        "        # For even more readability - add alternating row shading with increased height\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            if i % 2 == 0:  # Even rows\n",
        "                ax1.axhspan(i-0.5 - y_padding/2, i+0.5 + y_padding/2, color='#f5f5f5', alpha=0.3, zorder=0)\n",
        "\n",
        "        # Adjust circle size - INCREASED from previous version\n",
        "        base_size = 130  # Increased from 110 to make circles slightly bigger\n",
        "\n",
        "        # Calculate circle sizes based on maximum points\n",
        "        circle_sizes = {}\n",
        "        for i, max_p in enumerate(data['max_points']):\n",
        "            if max_p == 2:\n",
        "                circle_sizes[i] = base_size * 2  # 2 points get base size * 2\n",
        "            else:  # max_p == 3\n",
        "                circle_sizes[i] = base_size * 3  # 3 points get base size * 3\n",
        "\n",
        "        # Plot circles with size based on domain maximum points (consistent across columns)\n",
        "        for i, study_idx in enumerate(range(len(data['df_sorted']))):\n",
        "            for j, category_idx in enumerate(range(len(data['categories']))):\n",
        "                # Get the normalized value for color\n",
        "                normalized_value = data['sorted_normalized_matrix'][study_idx, category_idx]\n",
        "                # Get color from colormap\n",
        "                color = self.style.risk_cmap(normalized_value)\n",
        "\n",
        "                # Use pre-calculated size for this domain\n",
        "                circle_size = circle_sizes[category_idx]\n",
        "\n",
        "                # Create a circle using scatter plot\n",
        "                ax1.scatter(j, i, s=circle_size, c=[color], alpha=0.8,\n",
        "                          edgecolors='white', linewidths=0.5, zorder=2)\n",
        "\n",
        "        # Create y-axis labels (study names without risk level abbreviation)\n",
        "        y_labels = data['df_sorted']['Study'].values\n",
        "\n",
        "        # Set y-axis labels with increased font size\n",
        "        ax1.set_yticks(range(len(y_labels)))\n",
        "        ax1.set_yticklabels(y_labels, fontsize=8, rotation=0)\n",
        "        ax1.tick_params(axis='y', pad=25)\n",
        "\n",
        "        # Set x-axis labels horizontally with full category names\n",
        "        ax1.set_xticks(range(len(data['categories'])))\n",
        "\n",
        "        # Create x-labels - now vertical and on one line with proper point notation\n",
        "        x_labels = []\n",
        "        for cat, max_p in zip(data['categories'], data['max_points']):\n",
        "            # Simplified label format - single line, no breaks\n",
        "            if cat == \"Error Analysis\":\n",
        "                label = \"Error Analysis\"\n",
        "            elif cat == \"Fairness Assessment\":\n",
        "                label = \"Fairness Assessment\"\n",
        "            elif cat == \"Dataset Availability\":\n",
        "                label = \"Dataset Availability\"\n",
        "            elif cat == \"External Validation\":\n",
        "                label = \"External Validation\"\n",
        "            elif cat == \"Annotation Guidelines\":\n",
        "                label = \"Annotation Guidelines\"\n",
        "            elif cat == \"Code/Prompt Availability\":\n",
        "                label = \"Code/Prompt Availability\"\n",
        "            elif cat == \"Medical Condition Specificity\":\n",
        "                label = \"Medical Condition\"\n",
        "            else:\n",
        "                label = cat\n",
        "\n",
        "            # Add points notation\n",
        "            x_labels.append(f\"{label} ({max_p} pts)\")\n",
        "\n",
        "        # Set vertical x-axis labels with decreased font size\n",
        "        ax1.set_xticklabels(x_labels, rotation=90, ha='center', va='top', fontsize=8, fontweight='bold')\n",
        "        ax1.tick_params(axis='x', pad=7)\n",
        "        ax1.set_title('Domain Scores by Study', fontsize=9, fontweight='bold', pad=15)\n",
        "\n",
        "        # Set up the axes for the priority scores visualization with increased spacing\n",
        "        ax2.set_xlim(-0.5, 3-0.5)  # Now only 3 columns (High, Medium, Standard)\n",
        "        ax2.set_ylim(-0.5 - y_padding, num_studies-0.5 + y_padding)\n",
        "\n",
        "        # Add dotted light grid lines to priority scores visualization\n",
        "        ax2.set_axisbelow(True)\n",
        "        ax2.grid(which='both', linestyle=':', linewidth=0.5, color='#cccccc', alpha=0.7)\n",
        "\n",
        "        # Set up the axes for the total score visualization\n",
        "        ax3.set_xlim(-0.5, 0.5)  # Just one column\n",
        "        ax3.set_ylim(-0.5 - y_padding, num_studies-0.5 + y_padding)\n",
        "\n",
        "        # Add dotted light grid lines to total score visualization\n",
        "        ax3.set_axisbelow(True)\n",
        "        ax3.grid(which='both', linestyle=':', linewidth=0.5, color='#cccccc', alpha=0.7)\n",
        "\n",
        "        # Add shading to total score column\n",
        "        ax3.axvspan(-0.5, 0.5, color='#e6e6e6', alpha=0.7, zorder=0)\n",
        "\n",
        "        # For consistency - add same alternating row shading to both summary sections with increased height\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            if i % 2 == 0:  # Even rows\n",
        "                ax2.axhspan(i-0.5 - y_padding/2, i+0.5 + y_padding/2, color='#f5f5f5', alpha=0.3, zorder=0)\n",
        "                ax3.axhspan(i-0.5 - y_padding/2, i+0.5 + y_padding/2, color='#f5f5f5', alpha=0.3, zorder=0)\n",
        "\n",
        "        # Prepare data for summary visualizations\n",
        "        summary_data_priorities = np.zeros((len(data['df_sorted']), 3))\n",
        "        summary_data_priorities[:, 0] = data['df_sorted']['High Priority Score'].values / data['max_high_priority']\n",
        "        summary_data_priorities[:, 1] = data['df_sorted']['Medium Priority Score'].values / data['max_medium_priority']\n",
        "        summary_data_priorities[:, 2] = data['df_sorted']['Standard Priority Score'].values / data['max_standard_priority']\n",
        "\n",
        "        summary_data_total = np.zeros((len(data['df_sorted']), 1))\n",
        "        summary_data_total[:, 0] = data['df_sorted']['Total Score'].values / data['max_total']\n",
        "\n",
        "        # Use a larger size for all priority section circles\n",
        "        priority_circle_size = 290\n",
        "        total_circle_size = 310  # Slightly larger for total score\n",
        "\n",
        "        # Plot circles for priority scores\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            for j in range(3):  # 3 columns: High, Medium, Standard\n",
        "                normalized_value = summary_data_priorities[i, j]\n",
        "                color = self.style.risk_cmap(normalized_value)\n",
        "\n",
        "                # Create a circle using scatter plot\n",
        "                ax2.scatter(j, i, s=priority_circle_size, c=[color], alpha=0.8,\n",
        "                           edgecolors='white', linewidths=0.5, zorder=2)\n",
        "\n",
        "                # Add score text inside each circle\n",
        "                if j == 0:\n",
        "                    score = data['df_sorted']['High Priority Score'].iloc[i]\n",
        "                elif j == 1:\n",
        "                    score = data['df_sorted']['Medium Priority Score'].iloc[i]\n",
        "                else:  # j == 2\n",
        "                    score = data['df_sorted']['Standard Priority Score'].iloc[i]\n",
        "\n",
        "                ax2.text(j, i, str(int(score)), ha='center', va='center', fontsize=6,\n",
        "                        color='white', fontweight='bold', zorder=3)  # Text on top\n",
        "\n",
        "        # Plot circles for total score\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            normalized_value = summary_data_total[i, 0]\n",
        "            color = self.style.risk_cmap(normalized_value)\n",
        "\n",
        "            # Create a circle using scatter plot\n",
        "            ax3.scatter(0, i, s=total_circle_size, c=[color], alpha=0.8,\n",
        "                       edgecolors='white', linewidths=0.5, zorder=2)\n",
        "\n",
        "            # Add score text inside each circle\n",
        "            score = data['df_sorted']['Total Score'].iloc[i]\n",
        "            ax3.text(0, i, str(int(score)), ha='center', va='center', fontsize=6,\n",
        "                    color='white', fontweight='bold', zorder=3)  # Text on top\n",
        "\n",
        "        # Make priority scores x-axis labels vertical with decreased font\n",
        "        ax2.set_xticks(range(3))\n",
        "        ax2.set_xticklabels([\n",
        "            f'High Priority ({data[\"max_high_priority\"]})',\n",
        "            f'Medium Priority ({data[\"max_medium_priority\"]})',\n",
        "            f'Standard Priority ({data[\"max_standard_priority\"]})'\n",
        "        ], rotation=90, ha='center', va='top', fontsize=8, fontweight='bold')\n",
        "        ax2.tick_params(axis='x', pad=7)\n",
        "\n",
        "        # Set up total score x-axis label\n",
        "        ax3.set_xticks([0])\n",
        "        ax3.set_xticklabels([f'Total Score ({data[\"max_total\"]})'],\n",
        "                             rotation=90, ha='center', va='top', fontsize=8, fontweight='bold')\n",
        "        ax3.tick_params(axis='x', pad=7)\n",
        "\n",
        "        # Remove y-axis labels for summary sections\n",
        "        ax2.set_yticklabels(['' for _ in range(len(data['df_sorted']))])\n",
        "        ax3.set_yticklabels(['' for _ in range(len(data['df_sorted']))])\n",
        "\n",
        "        # Set titles for summary sections\n",
        "        ax2.set_title('Priority Scores', fontsize=9, fontweight='bold', pad=15)\n",
        "        ax3.set_title('Overall Score', fontsize=9, fontweight='bold', pad=15)\n",
        "\n",
        "        # Create legend for risk levels and circle sizes\n",
        "        from matplotlib.lines import Line2D\n",
        "        risk_legend_elements = [\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=self.style.color_palette['Low Risk'],\n",
        "                  markersize=12, label='Low Risk', markeredgecolor='white', markeredgewidth=0.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=self.style.color_palette['Medium Risk'],\n",
        "                  markersize=12, label='Medium Risk', markeredgecolor='white', markeredgewidth=0.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=self.style.color_palette['High Risk'],\n",
        "                  markersize=12, label='High Risk', markeredgecolor='white', markeredgewidth=0.5)\n",
        "        ]\n",
        "\n",
        "        # Create size legend only for the domain section\n",
        "        size_legend_elements = [\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor='#999999',\n",
        "                   markersize=np.sqrt(base_size * 2)/2.5, label='2 points',\n",
        "                   markeredgecolor='white', markeredgewidth=0.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor='#999999',\n",
        "                   markersize=np.sqrt(base_size * 3)/2.5, label='3 points',\n",
        "                   markeredgecolor='white', markeredgewidth=0.5)\n",
        "        ]\n",
        "\n",
        "        # Create the combined legend\n",
        "        all_legend_elements = risk_legend_elements + size_legend_elements\n",
        "        all_legend_labels = ['Low Risk', 'Medium Risk', 'High Risk', '2 points', '3 points']\n",
        "\n",
        "        # Add the combined legend with larger font\n",
        "        legend = legend_ax.legend(all_legend_elements, all_legend_labels,\n",
        "                               loc='center', fontsize=8, frameon=True,\n",
        "                               ncol=5, columnspacing=1.0,\n",
        "                               bbox_to_anchor=(0.5, 0.5))\n",
        "\n",
        "        # Move the title a bit closer to the plot\n",
        "        combined_fig.suptitle('Risk of Bias Assessment for LLMs Identifying SDoH',\n",
        "                             fontsize=12, fontweight='bold', y=0.92)\n",
        "\n",
        "        # Move criteria text a bit closer to the plot\n",
        "        criteria_text = \"\"\"Risk Criteria: Low: ≥14 total AND ≥6 High AND ≥3 Medium points | Medium: ≥9 total AND ≥4 High AND ≥2 Medium points | High: Below thresholds\"\"\"\n",
        "        combined_fig.text(0.5, 0.1, criteria_text, ha='center', fontsize=7,\n",
        "                        bbox={'facecolor': 'lightgrey', 'alpha': 0.5, 'pad': 5})\n",
        "\n",
        "        # Adjust layout to better accommodate all elements\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "\n",
        "        plt.savefig('risk_assessment_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('risk_assessment_heatmap.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_risk_distribution(self, data):\n",
        "        \"\"\"Creates bar chart of risk level distribution\"\"\"\n",
        "        # Count studies in each risk category\n",
        "        risk_counts = data['df']['Risk Level'].value_counts()\n",
        "\n",
        "        # Create a complete DataFrame with all risk levels\n",
        "        all_risk_levels = ['High Risk', 'Medium Risk', 'Low Risk']\n",
        "        complete_risk_counts = pd.Series(0, index=all_risk_levels)\n",
        "\n",
        "        # Update with actual counts\n",
        "        for level in risk_counts.index:\n",
        "            complete_risk_counts[level] = risk_counts[level]\n",
        "\n",
        "        # Sort in desired order\n",
        "        complete_risk_counts = complete_risk_counts.reindex(['High Risk', 'Medium Risk', 'Low Risk'])\n",
        "\n",
        "        plt.figure(figsize=(3.5, 2.5), facecolor=self.style.color_palette['background'])\n",
        "        bars = plt.bar(range(len(all_risk_levels)), complete_risk_counts.values,\n",
        "                       color=[self.style.color_palette[level] for level in all_risk_levels], width=0.6)\n",
        "\n",
        "        # Add count and percentage labels\n",
        "        for i, v in enumerate(complete_risk_counts.values):\n",
        "            if v > 0:\n",
        "                plt.text(i, v + 0.3, str(int(v)), ha='center', fontweight='bold', fontsize=7)\n",
        "                percentage = (v / len(data['studies'])) * 100\n",
        "                plt.text(i, v/2, f\"{percentage:.1f}%\", ha='center', va='center',\n",
        "                         color='white', fontweight='bold', fontsize=7)\n",
        "\n",
        "        plt.ylabel('Number of Studies', fontsize=8)\n",
        "        plt.title('Distribution of Studies by Risk Level', fontsize=9, fontweight='bold')\n",
        "        plt.ylim(0, max(complete_risk_counts.values) * 1.2 if max(complete_risk_counts.values) > 0 else 1)\n",
        "        plt.xticks(range(len(all_risk_levels)), ['High', 'Medium', 'Low'], fontsize=7)\n",
        "        plt.yticks(fontsize=7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('risk_level_distribution.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('risk_level_distribution.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_risk_by_year(self, data):\n",
        "        \"\"\"Creates stacked bar chart of risk levels by publication year\"\"\"\n",
        "        # Extract publication years from study names\n",
        "        years = []\n",
        "        for study in data['studies']:\n",
        "            year_part = study.split()[-1]\n",
        "            numeric_year = ''.join(c for c in year_part if c.isdigit())\n",
        "            years.append(int(numeric_year))\n",
        "\n",
        "        unique_years = sorted(set(years))\n",
        "\n",
        "        # Calculate risk level distribution by year\n",
        "        year_risk_data = {}\n",
        "        for year in unique_years:\n",
        "            year_indices = [i for i, y in enumerate(years) if y == year]\n",
        "            year_risk_levels = [data['df']['Risk Level'].iloc[i] for i in year_indices]\n",
        "            year_risk_counts = {'High Risk': 0, 'Medium Risk': 0, 'Low Risk': 0}\n",
        "            for risk in year_risk_levels:\n",
        "                year_risk_counts[risk] += 1\n",
        "            year_risk_data[year] = year_risk_counts\n",
        "\n",
        "        # Prepare data for stacked bar chart\n",
        "        years_for_plot = []\n",
        "        high_risk_counts = []\n",
        "        medium_risk_counts = []\n",
        "        low_risk_counts = []\n",
        "        study_counts = []\n",
        "\n",
        "        for year in unique_years:\n",
        "            years_for_plot.append(year)\n",
        "            high_risk_counts.append(year_risk_data[year]['High Risk'])\n",
        "            medium_risk_counts.append(year_risk_data[year]['Medium Risk'])\n",
        "            low_risk_counts.append(year_risk_data[year]['Low Risk'])\n",
        "            study_counts.append(sum(year_risk_data[year].values()))\n",
        "\n",
        "        # Create stacked bar chart\n",
        "        plt.figure(figsize=(4.5, 2.5), facecolor=self.style.color_palette['background'])\n",
        "        width = 0.6\n",
        "\n",
        "        p1 = plt.bar(years_for_plot, low_risk_counts, width, color=self.style.color_palette['Low Risk'], label='Low')\n",
        "        p2 = plt.bar(years_for_plot, medium_risk_counts, width,\n",
        "                     bottom=low_risk_counts, color=self.style.color_palette['Medium Risk'], label='Medium')\n",
        "        p3 = plt.bar(years_for_plot, high_risk_counts, width,\n",
        "                     bottom=[i+j for i,j in zip(low_risk_counts, medium_risk_counts)],\n",
        "                     color=self.style.color_palette['High Risk'], label='High')\n",
        "\n",
        "        # Add study count annotations\n",
        "        for i, count in enumerate(study_counts):\n",
        "            plt.text(years_for_plot[i], count + 0.2, f\"n={count}\", ha='center', fontsize=6)\n",
        "\n",
        "        plt.xlabel('Publication Year', fontsize=8)\n",
        "        plt.ylabel('Number of Studies', fontsize=8)\n",
        "        plt.title('Risk Levels by Publication Year', fontsize=9, fontweight='bold')\n",
        "        plt.xticks(years_for_plot, fontsize=7)\n",
        "        plt.yticks(fontsize=7)\n",
        "        plt.legend(fontsize=6, title=\"Risk\", title_fontsize=7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('risk_distribution_by_year.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('risk_distribution_by_year.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_domain_correlation(self, data):\n",
        "        \"\"\"Creates correlation heatmap between risk domains with complete, non-trimmed labels\"\"\"\n",
        "        # Normalize the scores for correlation calculation\n",
        "        normalized_scores = np.zeros_like(data['risk_matrix'], dtype=float)\n",
        "        for i, max_p in enumerate(data['max_points']):\n",
        "            normalized_scores[:, i] = data['risk_matrix'][:, i] / max_p\n",
        "\n",
        "        # Calculate correlation\n",
        "        corr_matrix = np.corrcoef(normalized_scores.T)\n",
        "        corr_df = pd.DataFrame(corr_matrix, index=data['categories'], columns=data['categories'])\n",
        "\n",
        "        # Create mask for lower triangle (including diagonal)\n",
        "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
        "\n",
        "        # Use the original full category names\n",
        "        category_labels = data['categories']\n",
        "\n",
        "        # Create a much larger figure to accommodate full-length labels\n",
        "        plt.figure(figsize=(11, 9), facecolor=self.style.color_palette['background'])\n",
        "\n",
        "        # Create custom color map\n",
        "        custom_cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "        # Create the heatmap with full original labels\n",
        "        heatmap = sns.heatmap(\n",
        "            corr_df,\n",
        "            annot=True,\n",
        "            cmap=custom_cmap,\n",
        "            vmin=-1,\n",
        "            vmax=1,\n",
        "            center=0,\n",
        "            linewidths=0.5,\n",
        "            fmt='.2f',\n",
        "            annot_kws={'size': 14},\n",
        "            mask=mask,\n",
        "            xticklabels=category_labels,\n",
        "            yticklabels=category_labels,\n",
        "            cbar_kws={'label': 'Correlation Coefficient'}\n",
        "        )\n",
        "\n",
        "        # Set x-axis labels with significant rotation and proper positioning\n",
        "        plt.xticks(rotation=45, ha='right', fontweight='bold', fontsize=12)\n",
        "\n",
        "        # Set y-axis labels\n",
        "        plt.yticks(rotation=0, va='center', fontweight='bold', fontsize=12)\n",
        "\n",
        "        # Adjust colorbar label\n",
        "        cbar = heatmap.collections[0].colorbar\n",
        "        cbar.ax.tick_params(labelsize=9)\n",
        "        cbar.set_label('Correlation Coefficient', fontsize=14)\n",
        "\n",
        "        # Add title with adjusted position\n",
        "        plt.title('Correlation Between Risk Domains', fontsize=14, fontweight='bold', pad=10)\n",
        "\n",
        "        # Add significant margins to ensure labels aren't cut off\n",
        "        plt.subplots_adjust(bottom=0.35, left=0.25)\n",
        "\n",
        "        # Save with extra padding to ensure no labels are trimmed\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('domain_correlation.png', dpi=300, bbox_inches='tight', pad_inches=0.5)\n",
        "        plt.savefig('domain_correlation.pdf', bbox_inches='tight', pad_inches=0.5)\n",
        "        plt.close()\n",
        "\n",
        "    def plot_score_scatter(self, data):\n",
        "        \"\"\"Creates scatter plot with larger points, elegant risk labels, and refined color schemes\n",
        "        with dynamic node positioning to avoid overlap and optimized connecting lines\"\"\"\n",
        "        # Import necessary modules\n",
        "        from matplotlib.lines import Line2D\n",
        "        import matplotlib.patheffects as path_effects\n",
        "        from scipy.spatial import distance\n",
        "        import numpy as np\n",
        "\n",
        "        # Extract and check data\n",
        "        df = data['df'].copy()  # Create a copy to avoid modifying the original\n",
        "\n",
        "        # Find overlapping points\n",
        "        coordinate_counts = df.groupby(['High Priority Score', 'Total Score']).size().reset_index(name='count')\n",
        "\n",
        "        # Create dictionary mapping coordinates to cluster size\n",
        "        cluster_sizes = {(row['High Priority Score'], row['Total Score']): row['count']\n",
        "                        for _, row in coordinate_counts.iterrows()}\n",
        "\n",
        "        # Print study count information\n",
        "        print(f\"Original dataset has {len(data['df'])} studies\")\n",
        "        print(f\"Number of unique (x,y) coordinates: {len(coordinate_counts)}\")\n",
        "\n",
        "        # Create larger figure with expanded axis limits\n",
        "        plt.figure(figsize=(12.0, 10.0), facecolor='white')\n",
        "\n",
        "        # Define distinct colors for each risk zone with more nuanced boundary colors\n",
        "        enhanced_colors = {\n",
        "            'Low Risk': '#1a9850',         # Green\n",
        "            'Medium Risk': '#fdae61',      # Orange/Yellow\n",
        "            'High Risk': '#d73027',        # Red\n",
        "            'Medium-High': '#f4a582',      # Lighter orange (boundary areas)\n",
        "            'High-Medium': '#d6604d',      # Lighter red (boundary areas)\n",
        "            'background': '#f8f9fa'        # Light gray background\n",
        "        }\n",
        "\n",
        "        # Expand the plot boundaries beyond the data range to create more space\n",
        "        x_min = -1.0\n",
        "        y_min = -1.0\n",
        "        x_max = data['max_high_priority'] + 1.0\n",
        "        y_max = data['max_total'] + 2.0\n",
        "\n",
        "        # Create smooth gradient background for risk zones\n",
        "        from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "        # Define custom colormaps for each risk zone\n",
        "        high_risk_cmap = LinearSegmentedColormap.from_list('high_risk', ['#ffebee', '#ffcdd2'])\n",
        "        medium_risk_cmap = LinearSegmentedColormap.from_list('medium_risk', ['#fff8e1', '#ffecb3'])\n",
        "        low_risk_cmap = LinearSegmentedColormap.from_list('low_risk', ['#e8f5e9', '#c8e6c9'])\n",
        "\n",
        "        # Create background with gradient shading across expanded area\n",
        "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                            np.linspace(y_min, y_max, 100))\n",
        "\n",
        "        # Define risk zones across expanded area\n",
        "        high_risk_mask = ((xx < 4) | ((xx < 6) & (yy < 9)))\n",
        "        medium_risk_mask = ((xx >= 4) & (xx < 6) & (yy >= 9) & (yy < 14)) | ((xx >= 6) & (yy < 14))\n",
        "        low_risk_mask = (xx >= 6) & (yy >= 14)\n",
        "\n",
        "        # Plot the risk zone backgrounds with slight transparency\n",
        "        plt.imshow(np.zeros_like(xx), extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0, aspect='auto')  # Create correct extent\n",
        "\n",
        "        plt.imshow(high_risk_mask, extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0.15, aspect='auto', cmap=high_risk_cmap, origin='lower')\n",
        "        plt.imshow(medium_risk_mask, extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0.15, aspect='auto', cmap=medium_risk_cmap, origin='lower')\n",
        "        plt.imshow(low_risk_mask, extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0.15, aspect='auto', cmap=low_risk_cmap, origin='lower')\n",
        "\n",
        "        # Add subtle grid lines\n",
        "        plt.grid(True, linestyle='-', linewidth=0.6, alpha=0.15, color='#bdbdbd')\n",
        "\n",
        "        # CORRECTED: Re-calculate risk levels based on criteria with detailed subcategories\n",
        "        df['Corrected Risk Level'] = 'High Risk'  # Default to high risk\n",
        "\n",
        "        # Medium risk: ≥9 total AND ≥4 High\n",
        "        medium_mask = (df['Total Score'] >= 9) & (df['High Priority Score'] >= 4)\n",
        "        df.loc[medium_mask, 'Corrected Risk Level'] = 'Medium Risk'\n",
        "\n",
        "        # Low risk: ≥14 total AND ≥6 High\n",
        "        low_mask = (df['Total Score'] >= 14) & (df['High Priority Score'] >= 6)\n",
        "        df.loc[low_mask, 'Corrected Risk Level'] = 'Low Risk'\n",
        "\n",
        "        # Add nuanced risk levels for boundary areas\n",
        "        # High-Medium: High priority is good (≥4) but total is below medium threshold (<9)\n",
        "        high_medium_mask = (df['High Priority Score'] >= 4) & (df['Total Score'] < 9)\n",
        "        df.loc[high_medium_mask, 'Corrected Risk Level'] = 'High-Medium'\n",
        "\n",
        "        # Medium-High: Total score is good (≥9) but high priority is below medium threshold (<4)\n",
        "        medium_high_mask = (df['Total Score'] >= 9) & (df['High Priority Score'] < 4)\n",
        "        df.loc[medium_high_mask, 'Corrected Risk Level'] = 'Medium-High'\n",
        "\n",
        "        # Plot each unique coordinate point\n",
        "        point_positions = []  # Store positions of all points\n",
        "        for _, row in coordinate_counts.iterrows():\n",
        "            x = row['High Priority Score']\n",
        "            y = row['Total Score']\n",
        "            count = row['count']\n",
        "\n",
        "            # Store point position\n",
        "            point_positions.append((x, y))\n",
        "\n",
        "            # Get representative risk level for this cluster (using first study at this position)\n",
        "            cluster_df = df[(df['High Priority Score'] == x) & (df['Total Score'] == y)]\n",
        "            risk_level = cluster_df['Corrected Risk Level'].iloc[0]\n",
        "            color = enhanced_colors[risk_level]\n",
        "\n",
        "            # Create scatter plot with LARGER points and clean styling\n",
        "            scatter = plt.scatter(x, y,\n",
        "                              c=[color],\n",
        "                              alpha=1.0, s=750,  # Large points\n",
        "                              edgecolors='black', linewidths=2.0,\n",
        "                              zorder=10)\n",
        "\n",
        "            # For points with multiple studies, add a count indicator\n",
        "            if count > 1:\n",
        "                plt.text(x, y, str(count), ha='center', va='center',\n",
        "                      color='white', fontsize=10, fontweight='bold', zorder=15)\n",
        "\n",
        "        # Create simplified labels\n",
        "        simple_labels = []\n",
        "        for study in df['Study']:\n",
        "            parts = study.split()\n",
        "            if len(parts) > 1:\n",
        "                name = parts[0]\n",
        "                year = parts[-1]\n",
        "                simple_labels.append(f\"{name} {year}\")\n",
        "            else:\n",
        "                simple_labels.append(study)\n",
        "\n",
        "        # Add simplified labels to dataframe\n",
        "        df['Simple_Label'] = simple_labels\n",
        "\n",
        "        # IMPROVED LABEL POSITIONING ALGORITHM WITH SHORTER STALKS\n",
        "\n",
        "        # Parameters for callout line style\n",
        "        callout_style = {'color': 'black', 'linewidth': 0.5, 'alpha': 0.7, 'zorder': 5}  # Thinner lines\n",
        "\n",
        "        # 1. Group studies by their coordinates\n",
        "        grouped_studies = df.groupby(['High Priority Score', 'Total Score'])\n",
        "\n",
        "        # Store all text objects and their associated lines\n",
        "        all_texts = []\n",
        "        all_lines = []\n",
        "        text_to_point = {}  # Map texts to their anchor points\n",
        "        label_bboxes = {}   # Store bounding boxes for label overlap detection\n",
        "\n",
        "        # 2. Improved dynamic label positioning function with SHORTER STALKS\n",
        "        def get_optimal_position(x, y, cluster_size, point_idx, total_points, other_points):\n",
        "            \"\"\"\n",
        "            Dynamically calculate optimal label position with shorter stalks based on:\n",
        "            - Point location in the chart\n",
        "            - Cluster size\n",
        "            - Index within cluster\n",
        "            - Positions of other points (to avoid overlap)\n",
        "            \"\"\"\n",
        "            # Base radius - SIGNIFICANTLY REDUCED for shorter stalks\n",
        "            base_radius = 0.45 + (0.05 * min(cluster_size - 1, 4))  # Much shorter stalks\n",
        "\n",
        "            # Special handling for regions with known overlap issues\n",
        "            if (x > 7 and y > 12) or (2 < x < 4 and 3 < y < 5) or (x == 3 and y == 5):\n",
        "                base_radius = 0.7  # Slightly longer stalks for problematic regions\n",
        "\n",
        "            if cluster_size == 1:\n",
        "                # For single points, position based on octants (8 directions)\n",
        "\n",
        "                # Determine octant (0-7) based on position in chart\n",
        "                chart_x_ratio = (x - x_min) / (x_max - x_min)  # 0 to 1\n",
        "                chart_y_ratio = (y - y_min) / (y_max - y_min)  # 0 to 1\n",
        "\n",
        "                # Choose direction based on position in chart - with shorter distances\n",
        "                if chart_x_ratio < 0.25:\n",
        "                    # Left quarter\n",
        "                    if chart_y_ratio < 0.25:\n",
        "                        dx, dy = 0.6, 0.2  # Bottom left - go right and slightly up\n",
        "                    elif chart_y_ratio < 0.5:\n",
        "                        dx, dy = 0.6, 0.0  # Middle-lower left - go right\n",
        "                    elif chart_y_ratio < 0.75:\n",
        "                        dx, dy = 0.6, 0.0  # Middle-upper left - go right\n",
        "                    else:\n",
        "                        dx, dy = 0.5, -0.3  # Top left - go right and down\n",
        "                elif chart_x_ratio < 0.5:\n",
        "                    # Middle-left quarter\n",
        "                    if chart_y_ratio < 0.25:\n",
        "                        dx, dy = 0.0, 0.6  # Bottom middle-left - go up\n",
        "                    elif chart_y_ratio < 0.5:\n",
        "                        dx, dy = 0.5, 0.4  # Middle-lower middle-left - go up-right\n",
        "                    elif chart_y_ratio < 0.75:\n",
        "                        dx, dy = 0.4, -0.4  # Middle-upper middle-left - go down-right\n",
        "                    else:\n",
        "                        dx, dy = 0.0, -0.6  # Top middle-left - go down\n",
        "                elif chart_x_ratio < 0.75:\n",
        "                    # Middle-right quarter\n",
        "                    if chart_y_ratio < 0.25:\n",
        "                        dx, dy = 0.0, 0.6  # Bottom middle-right - go up\n",
        "                    elif chart_y_ratio < 0.5:\n",
        "                        dx, dy = -0.5, 0.4  # Middle-lower middle-right - go up-left\n",
        "                    elif chart_y_ratio < 0.75:\n",
        "                        dx, dy = -0.4, -0.4  # Middle-upper middle-right - go down-left\n",
        "                    else:\n",
        "                        dx, dy = 0.0, -0.6  # Top middle-right - go down\n",
        "                else:\n",
        "                    # Right quarter\n",
        "                    if chart_y_ratio < 0.25:\n",
        "                        dx, dy = -0.5, 0.3  # Bottom right - go left and up\n",
        "                    elif chart_y_ratio < 0.5:\n",
        "                        dx, dy = -0.6, 0.0  # Middle-lower right - go left\n",
        "                    elif chart_y_ratio < 0.75:\n",
        "                        dx, dy = -0.6, 0.0  # Middle-upper right - go left\n",
        "                    else:\n",
        "                        dx, dy = -0.5, -0.3  # Top right - go left and down\n",
        "\n",
        "                # Scale by base_radius\n",
        "                dx *= base_radius\n",
        "                dy *= base_radius\n",
        "\n",
        "                # Set text alignment\n",
        "                ha = 'right' if dx < -0.1 else ('center' if abs(dx) <= 0.1 else 'left')\n",
        "                va = 'top' if dy < -0.1 else ('center' if abs(dy) <= 0.1 else 'bottom')\n",
        "\n",
        "                return dx, dy, ha, va\n",
        "            else:\n",
        "                # For clusters, arrange in a well-separated pattern using more directions\n",
        "\n",
        "                # Calculate how many items to place in each direction\n",
        "                # For large clusters, use 16 directions for better spacing\n",
        "                if cluster_size > 4 or (x == 3 and y == 5):  # Special handling for node at (3,5)\n",
        "                    directions = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE',\n",
        "                                'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\n",
        "                else:\n",
        "                    directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
        "\n",
        "                # Distribute items evenly across directions\n",
        "                items_per_direction = [total_points // len(directions) + (1 if i < total_points % len(directions) else 0)\n",
        "                                    for i in range(len(directions))]\n",
        "\n",
        "                # Find which direction this item belongs to\n",
        "                direction_idx = 0\n",
        "                count = 0\n",
        "                for i, num_items in enumerate(items_per_direction):\n",
        "                    count += num_items\n",
        "                    if point_idx < count:\n",
        "                        direction_idx = i\n",
        "                        break\n",
        "\n",
        "                # Calculate position based on direction\n",
        "                if len(directions) == 16:\n",
        "                    angles = {\n",
        "                        'N': np.pi/2, 'NNE': 5*np.pi/8, 'NE': 3*np.pi/4, 'ENE': 7*np.pi/8,\n",
        "                        'E': 0, 'ESE': -np.pi/8, 'SE': -np.pi/4, 'SSE': -3*np.pi/8,\n",
        "                        'S': -np.pi/2, 'SSW': -5*np.pi/8, 'SW': -3*np.pi/4, 'WSW': -7*np.pi/8,\n",
        "                        'W': np.pi, 'WNW': 7*np.pi/8, 'NW': 5*np.pi/4, 'NNW': 3*np.pi/8\n",
        "                    }\n",
        "                else:\n",
        "                    angles = {\n",
        "                        'N': np.pi/2, 'NE': np.pi/4, 'E': 0, 'SE': -np.pi/4,\n",
        "                        'S': -np.pi/2, 'SW': -3*np.pi/4, 'W': np.pi, 'NW': 3*np.pi/4\n",
        "                    }\n",
        "\n",
        "                angle = angles[directions[direction_idx]]\n",
        "\n",
        "                # Add slight variation within each direction\n",
        "                # Calculate which item this is within its direction\n",
        "                local_idx = point_idx - (count - items_per_direction[direction_idx])\n",
        "                max_local = items_per_direction[direction_idx]\n",
        "\n",
        "                if max_local > 1:\n",
        "                    spread = np.pi/(6 * len(directions))  # Smaller spread for more directions\n",
        "                    angle += spread * (2 * local_idx / (max_local - 1) - 1)\n",
        "\n",
        "                # Calculate position with SHORT stalks scaled by cluster size\n",
        "                if cluster_size >= 5:\n",
        "                    # For very large clusters, need a bit more space\n",
        "                    stalk_length = 0.6\n",
        "                else:\n",
        "                    stalk_length = 0.4 + 0.05 * cluster_size  # Much shorter baseline\n",
        "\n",
        "                dx = stalk_length * np.cos(angle)\n",
        "                dy = stalk_length * np.sin(angle)\n",
        "\n",
        "                # Set text alignment based on angle\n",
        "                ha = 'left' if -np.pi/2 < angle < np.pi/2 else 'right'\n",
        "                va = 'bottom' if 0 < angle < np.pi else 'top'\n",
        "\n",
        "                # Adjust for near-axis points\n",
        "                if abs(dx) < 0.1:\n",
        "                    ha = 'center'\n",
        "                if abs(dy) < 0.1:\n",
        "                    va = 'center'\n",
        "\n",
        "                return dx, dy, ha, va\n",
        "\n",
        "        # 3. Improved function to add text with better positioning\n",
        "        def add_optimized_callout(x, y, label, color, cluster_size, point_idx, total_points, other_points):\n",
        "            # Get optimal position\n",
        "            dx, dy, ha, va = get_optimal_position(x, y, cluster_size, point_idx, total_points, other_points)\n",
        "\n",
        "            # Create text with BLACK outline\n",
        "            text = plt.text(x + dx, y + dy, label,\n",
        "                          fontsize=7.5,  # Smaller font size for less overlap\n",
        "                          fontweight='bold',\n",
        "                          color=color, ha=ha, va=va, zorder=15,\n",
        "                          path_effects=[path_effects.withStroke(linewidth=0.1, foreground='black')])\n",
        "\n",
        "            # Add a simple straight line (no bezier curves) - shorter stalks are cleaner with straight lines\n",
        "            line = plt.plot([x, x + dx], [y, y + dy], **callout_style)[0]\n",
        "\n",
        "            # Store the relationship between text and its anchor point\n",
        "            text_to_point[text] = (x, y)\n",
        "\n",
        "            return text, line, (x + dx, y + dy)  # Return text position for overlap checking\n",
        "\n",
        "        # 4. First pass: position labels without considering overlaps\n",
        "        label_positions = {}  # Store label positions by (x,y) point\n",
        "\n",
        "        for (x, y), group in grouped_studies:\n",
        "            cluster_size = len(group)\n",
        "            label_positions[(x, y)] = []\n",
        "\n",
        "            # For each study in this cluster\n",
        "            for idx, (_, row) in enumerate(group.iterrows()):\n",
        "                label = row['Simple_Label']\n",
        "                color = enhanced_colors[row['Corrected Risk Level']]\n",
        "\n",
        "                # Add optimized positioned text and line\n",
        "                text, line, pos = add_optimized_callout(x, y, label, color, cluster_size, idx, cluster_size, point_positions)\n",
        "                all_texts.append(text)\n",
        "                all_lines.append(line)\n",
        "                label_positions[(x, y)].append(pos)  # Store position for this label\n",
        "\n",
        "        # 5. Get bounding boxes for all text objects\n",
        "        from matplotlib.transforms import Bbox\n",
        "\n",
        "        def get_text_bbox(text):\n",
        "            \"\"\"Get the bounding box of a text object in data coordinates\"\"\"\n",
        "            renderer = plt.gcf().canvas.get_renderer()\n",
        "            bbox = text.get_window_extent(renderer)\n",
        "            # Add padding to bounding box for better spacing\n",
        "            bbox = bbox.expanded(1.2, 1.2)  # 20% padding - more aggressive\n",
        "            bbox_data = bbox.transformed(plt.gca().transData.inverted())\n",
        "            return bbox_data\n",
        "\n",
        "        # 6. Improved overlap resolution with many iterations and more aggressive separation\n",
        "        for iteration in range(7):  # More iterations for better results\n",
        "            overlaps_resolved = 0\n",
        "\n",
        "            for i, text1 in enumerate(all_texts):\n",
        "                bbox1 = get_text_bbox(text1)\n",
        "                text1_pos = text1.get_position()\n",
        "\n",
        "                # Get the anchor point for this text\n",
        "                anchor_x, anchor_y = text_to_point[text1]\n",
        "\n",
        "                # Check for overlaps with other texts\n",
        "                for j, text2 in enumerate(all_texts):\n",
        "                    if i != j:  # Don't compare with self\n",
        "                        bbox2 = get_text_bbox(text2)\n",
        "\n",
        "                        # Check if bounding boxes overlap\n",
        "                        if bbox1.overlaps(bbox2):\n",
        "                            overlaps_resolved += 1\n",
        "\n",
        "                            # Get the anchor point for text2\n",
        "                            anchor2_x, anchor2_y = text_to_point[text2]\n",
        "\n",
        "                            # Calculate vector from text2 to text1\n",
        "                            vec = np.array([text1_pos[0] - text2.get_position()[0],\n",
        "                                          text1_pos[1] - text2.get_position()[1]])\n",
        "\n",
        "                            # If vector is very small, choose a random direction\n",
        "                            if np.linalg.norm(vec) < 0.01:\n",
        "                                angle = np.random.uniform(0, 2*np.pi)\n",
        "                                vec = np.array([np.cos(angle), np.sin(angle)])\n",
        "                            else:\n",
        "                                vec = vec / np.linalg.norm(vec)  # Normalize\n",
        "\n",
        "                            # Move text1 away from overlap - MORE AGGRESSIVE SEPARATION\n",
        "                            offset = 0.4  # Larger offset for more aggressive separation\n",
        "                            new_pos = (text1_pos[0] + offset * vec[0],\n",
        "                                      text1_pos[1] + offset * vec[1])\n",
        "\n",
        "                            # Make sure new position isn't too far from original point\n",
        "                            current_dist = np.sqrt((new_pos[0] - anchor_x)**2 + (new_pos[1] - anchor_y)**2)\n",
        "                            max_dist = 1.5  # Maximum allowed distance - REDUCED\n",
        "                            if current_dist > max_dist:\n",
        "                                scale_factor = max_dist / current_dist\n",
        "                                new_pos = (anchor_x + (new_pos[0] - anchor_x) * scale_factor,\n",
        "                                        anchor_y + (new_pos[1] - anchor_y) * scale_factor)\n",
        "\n",
        "                            text1.set_position(new_pos)\n",
        "\n",
        "                            # Update straight line\n",
        "                            all_lines[i].set_data([anchor_x, new_pos[0]], [anchor_y, new_pos[1]])\n",
        "\n",
        "                            # Update bbox1 after moving\n",
        "                            bbox1 = get_text_bbox(text1)\n",
        "\n",
        "                # Also check for overlap with points (not just other labels)\n",
        "                for px, py in point_positions:\n",
        "                    # Create a small bbox around the point\n",
        "                    point_bbox = Bbox.from_extents(px-0.25, py-0.25, px+0.25, py+0.25)\n",
        "\n",
        "                    if bbox1.overlaps(point_bbox) and (px, py) != (anchor_x, anchor_y):\n",
        "                        # Move text away from the point\n",
        "                        vec = np.array([text1_pos[0] - px, text1_pos[1] - py])\n",
        "                        if np.linalg.norm(vec) > 0:\n",
        "                            vec = vec / np.linalg.norm(vec)\n",
        "                        else:\n",
        "                            angle = np.random.uniform(0, 2*np.pi)\n",
        "                            vec = np.array([np.cos(angle), np.sin(angle)])\n",
        "\n",
        "                        offset = 0.35\n",
        "                        new_pos = (text1_pos[0] + offset * vec[0],\n",
        "                                  text1_pos[1] + offset * vec[1])\n",
        "\n",
        "                        # Limit how far we can move\n",
        "                        current_dist = np.sqrt((new_pos[0] - anchor_x)**2 + (new_pos[1] - anchor_y)**2)\n",
        "                        max_dist = 1.5  # REDUCED max distance\n",
        "                        if current_dist > max_dist:\n",
        "                            scale_factor = max_dist / current_dist\n",
        "                            new_pos = (anchor_x + (new_pos[0] - anchor_x) * scale_factor,\n",
        "                                    anchor_y + (new_pos[1] - anchor_y) * scale_factor)\n",
        "\n",
        "                        text1.set_position(new_pos)\n",
        "\n",
        "                        # Update the straight line\n",
        "                        all_lines[i].set_data([anchor_x, new_pos[0]], [anchor_y, new_pos[1]])\n",
        "\n",
        "                        # Update bbox1\n",
        "                        bbox1 = get_text_bbox(text1)\n",
        "\n",
        "            # If very few overlaps were resolved in this iteration, we can stop\n",
        "            if overlaps_resolved < 3:\n",
        "                break\n",
        "\n",
        "        # 7. Final check: find and fix any remaining overlaps with more aggressive moves\n",
        "        # This is a final, brute-force pass to eliminate any stubborn overlaps\n",
        "        for i, text1 in enumerate(all_texts):\n",
        "            bbox1 = get_text_bbox(text1)\n",
        "            text1_pos = text1.get_position()\n",
        "            anchor_x, anchor_y = text_to_point[text1]\n",
        "\n",
        "            for j, text2 in enumerate(all_texts):\n",
        "                if i != j:\n",
        "                    bbox2 = get_text_bbox(text2)\n",
        "\n",
        "                    if bbox1.overlaps(bbox2):\n",
        "                        # Calculate vector from text2 to text1\n",
        "                        vec = np.array([text1_pos[0] - text2.get_position()[0],\n",
        "                                      text1_pos[1] - text2.get_position()[1]])\n",
        "\n",
        "                        # If too close, pick a random direction\n",
        "                        if np.linalg.norm(vec) < 0.01:\n",
        "                            angle = np.random.uniform(0, 2*np.pi)\n",
        "                            vec = np.array([np.cos(angle), np.sin(angle)])\n",
        "                        else:\n",
        "                            vec = vec / np.linalg.norm(vec)\n",
        "\n",
        "                        # VERY aggressive separation\n",
        "                        offset = 0.5\n",
        "                        new_pos = (text1_pos[0] + offset * vec[0],\n",
        "                                  text1_pos[1] + offset * vec[1])\n",
        "\n",
        "                        text1.set_position(new_pos)\n",
        "                        all_lines[i].set_data([anchor_x, new_pos[0]], [anchor_y, new_pos[1]])\n",
        "                        bbox1 = get_text_bbox(text1)\n",
        "\n",
        "        # 8. Final pass to ensure no labels are outside plot boundaries\n",
        "        for i, text in enumerate(all_texts):\n",
        "            pos = text.get_position()\n",
        "            anchor_x, anchor_y = text_to_point[text]\n",
        "\n",
        "            # Check if text is outside boundaries and move it inside\n",
        "            # Add some padding to the boundaries\n",
        "            padding = 0.3\n",
        "            moved = False\n",
        "            new_pos = list(pos)\n",
        "\n",
        "            if pos[0] < x_min + padding:\n",
        "                new_pos[0] = x_min + padding\n",
        "                moved = True\n",
        "            elif pos[0] > x_max - padding:\n",
        "                new_pos[0] = x_max - padding\n",
        "                moved = True\n",
        "\n",
        "            if pos[1] < y_min + padding:\n",
        "                new_pos[1] = y_min + padding\n",
        "                moved = True\n",
        "            elif pos[1] > y_max - padding:\n",
        "                new_pos[1] = y_max - padding\n",
        "                moved = True\n",
        "\n",
        "            if moved:\n",
        "                text.set_position(new_pos)\n",
        "                all_lines[i].set_data([anchor_x, new_pos[0]], [anchor_y, new_pos[1]])\n",
        "\n",
        "        # Add threshold lines with elegant styling\n",
        "        plt.axhline(y=14, color=enhanced_colors['Low Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "        plt.axhline(y=9, color=enhanced_colors['Medium Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "        plt.axvline(x=6, color=enhanced_colors['Low Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "        plt.axvline(x=4, color=enhanced_colors['Medium Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "\n",
        "        # Add risk region labels with subtle effects\n",
        "        text_effects = [\n",
        "            path_effects.Stroke(linewidth=3, foreground='white', alpha=0.8),\n",
        "            path_effects.Normal()\n",
        "        ]\n",
        "\n",
        "        # Low Risk - positioned in the upper right corner\n",
        "        low_text = plt.text(9.2, 18, \"Low Risk\",\n",
        "                          fontsize=28,\n",
        "                          ha='center', va='center',\n",
        "                          color=enhanced_colors['Low Risk'],\n",
        "                          fontweight='bold', alpha=0.6,\n",
        "                          path_effects=text_effects,\n",
        "                          zorder=5)\n",
        "\n",
        "        # Medium Risk - positioned to avoid data points\n",
        "        med_text = plt.text(8.2, 12.5, \"Medium Risk\",\n",
        "                          fontsize=28,\n",
        "                          ha='center', va='center',\n",
        "                          color=enhanced_colors['Medium Risk'],\n",
        "                          fontweight='bold', alpha=0.6,\n",
        "                          path_effects=text_effects,\n",
        "                          zorder=5)\n",
        "\n",
        "        # High Risk - positioned in the bottom left corner\n",
        "        high_text = plt.text(0.5, 1.5, \"High Risk\",\n",
        "                            fontsize=28,\n",
        "                            ha='center', va='center',\n",
        "                            color=enhanced_colors['High Risk'],\n",
        "                            fontweight='bold', alpha=0.6,\n",
        "                            path_effects=text_effects,\n",
        "                            zorder=5)\n",
        "\n",
        "        # Add legends with elegant styling\n",
        "        legend_elements = [\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['Low Risk'],\n",
        "                  markersize=12, label='Low Risk', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['Medium Risk'],\n",
        "                  markersize=12, label='Medium Risk', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['High Risk'],\n",
        "                  markersize=12, label='High Risk', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            # Add boundary region colors to the legend\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['Medium-High'],\n",
        "                  markersize=12, label='Medium-High', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['High-Medium'],\n",
        "                  markersize=12, label='High-Medium', markeredgecolor='black', markeredgewidth=1.5),\n",
        "        ]\n",
        "\n",
        "        # Legend for risk levels with improved styling\n",
        "        legend = plt.legend(handles=legend_elements, loc='upper left', fontsize=10,\n",
        "                          title='Risk Level', title_fontsize=11,\n",
        "                          framealpha=0.9, edgecolor='#d4d4d4')\n",
        "\n",
        "        # Style the plot borders and ticks\n",
        "        ax = plt.gca()\n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_visible(True)\n",
        "            spine.set_color('#d4d4d4')\n",
        "            spine.set_linewidth(0.8)\n",
        "\n",
        "        # Add more elegant tick styling\n",
        "        ax.tick_params(axis='both', which='major', labelsize=10, colors='#505050', length=5, width=0.8)\n",
        "\n",
        "        # Add an elegant title\n",
        "        plt.title('Relationship Between High Priority Score and Total Score',\n",
        "                fontsize=16, fontweight='bold', color='#202020', pad=15)\n",
        "\n",
        "        # Make x and y labels more informative\n",
        "        plt.xlabel('High Priority Score (max 9)', fontsize=12, fontweight='bold', color='#303030')\n",
        "        plt.ylabel('Total Score (max 18)', fontsize=12, fontweight='bold', color='#303030')\n",
        "\n",
        "        # Set expanded axis limits to create more space\n",
        "        plt.xlim(x_min, x_max)\n",
        "        plt.ylim(y_min, y_max)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Add a note about threshold criteria with elegant styling\n",
        "        plt.subplots_adjust(bottom=0.12)  # Create more space at bottom\n",
        "\n",
        "        threshold_note = \"Risk Criteria: Low: ≥14 total AND ≥6 High | Medium: ≥9 total AND ≥4 High | High: Below thresholds\"\n",
        "        plt.figtext(0.5, 0.02, threshold_note, ha='center', fontsize=9, color='#505050',\n",
        "                  bbox=dict(facecolor='#f5f5f5', edgecolor='#d4d4d4', linewidth=0.5,\n",
        "                          alpha=0.95, boxstyle='round,pad=0.4,rounding_size=0.2'))\n",
        "\n",
        "        plt.savefig('high_priority_vs_total_score.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('high_priority_vs_total_score.svg', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "#########################################\n",
        "# MAIN FUNCTION\n",
        "#########################################\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the analysis and generate all visualizations\"\"\"\n",
        "    # Initialize style settings\n",
        "    style = PlotStyle()\n",
        "\n",
        "    # Define study data (can be loaded from external source)\n",
        "    study_data = {\n",
        "        'studies': [\n",
        "            \"Patra 2025\", \"Kim 2025\", \"Scherbakov 2025\", \"Rabbani 2024\", \"Shah-Mohammadi 2024a\",\n",
        "            \"Gu 2024\", \"Shah-Mohammadi 2024b\", \"Huang 2024\", \"Roosan 2024a\", \"Fu 2024\",\n",
        "            \"Guevara 2024\", \"Madrid-García 2024\", \"Yu 2024\", \"Peng 2024\", \"Sushil 2024\",\n",
        "            \"Keloth 2024\", \"Kwon 2024\", \"Holmes 2024\", \"Roosan 2024b\", \"Petit-Jean 2024\",\n",
        "            \"Roy 2024\", \"Gabriel 2024\", \"Robitschek 2024\", \"Ralevski 2024\", \"Yao 2023\",\n",
        "            \"Ramachandran 2023\", \"Turchin 2023\", \"Wang 2023\", \"Richie 2023\", \"Bhate 2023\",\n",
        "            \"Kim 2023\", \"Lituiev 2022\", \"Kugic 2022\", \"Botelle 2022\", \"Han 2022\"\n",
        "        ],\n",
        "        'categories': [\n",
        "            \"Error Analysis\", \"Fairness Assessment\", \"Annotation Guidelines\",\n",
        "            \"External Validation\", \"Medical Condition Specificity\",\n",
        "            \"Code/Prompt Availability\", \"Dataset Availability\"\n",
        "        ],\n",
        "        'priority_levels': [\n",
        "            \"High\", \"High\", \"High\",\n",
        "            \"Medium\", \"Medium\",\n",
        "            \"Standard\", \"Standard\"\n",
        "        ],\n",
        "        'max_points': [3, 3, 3, 3, 2, 2, 2],\n",
        "        'scores': {\n",
        "            \"Error Analysis\": [3 if x == 1 else 0 for x in [1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]],\n",
        "            \"Fairness Assessment\": [3 if x == 1 else 0 for x in [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
        "            \"Annotation Guidelines\": [3 if x == 1 else 0 for x in [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]],\n",
        "            \"External Validation\": [3 if x == 1 else 0 for x in [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
        "            \"Medical Condition Specificity\": [2 if x == 1 else 0 for x in [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]],\n",
        "            \"Code/Prompt Availability\": [2 if x == 1 else 0 for x in [1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
        "            \"Dataset Availability\": [2 if x == 1 else 0 for x in [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Prepare data\n",
        "    processor = DataProcessor(study_data)\n",
        "    processed_data = processor.processed_data\n",
        "\n",
        "    # Initialize visualizer\n",
        "    visualizer = Visualizer(style)\n",
        "\n",
        "    # Generate all visualizations\n",
        "    visualizer.plot_domain_completion(processed_data)\n",
        "    visualizer.plot_risk_assessment_heatmap(processed_data)\n",
        "    visualizer.plot_risk_distribution(processed_data)\n",
        "    visualizer.plot_risk_by_year(processed_data)\n",
        "    visualizer.plot_domain_correlation(processed_data)\n",
        "    visualizer.plot_score_scatter(processed_data)\n",
        "\n",
        "    print(\"All visualizations have been generated successfully.\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "KzoUWpzny1mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from matplotlib.lines import Line2D\n",
        "import matplotlib.patheffects as path_effects\n",
        "from matplotlib.transforms import Bbox\n",
        "\n",
        "# Install adjustText if not available\n",
        "try:\n",
        "    from adjustText import adjust_text\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"adjustText\"])\n",
        "    from adjustText import adjust_text\n",
        "\n",
        "#########################################\n",
        "# CONFIGURATION AND STYLING\n",
        "#########################################\n",
        "\n",
        "class PlotStyle:\n",
        "    \"\"\"Class to manage plot styling and color palettes\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.color_palette = {\n",
        "            'High Risk': '#e41a1c',     # Bright red (Nature standard)\n",
        "            'Medium Risk': '#ff9900',   # Orange (Nature standard)\n",
        "            'Low Risk': '#4daf4a',      # Green (Nature standard)\n",
        "            'primary_blue': '#377eb8',  # Nature standard blue\n",
        "            'secondary_blue': '#80b1d3', # Lighter blue\n",
        "            'light_blue': '#deebf7',    # Very light blue\n",
        "            'background': '#ffffff',    # White background\n",
        "            'grid': '#e6e6e6',          # Light gray grid\n",
        "            'text': '#3c3c3c',          # Dark gray text\n",
        "            'accent1': '#984ea3',       # Purple (Nature standard)\n",
        "            'accent2': '#a65628',       # Brown (Nature standard)\n",
        "            'accent3': '#f781bf'        # Pink (Nature standard)\n",
        "        }\n",
        "\n",
        "        self.risk_cmap = self._create_risk_colormap()\n",
        "        self._set_plot_parameters()\n",
        "\n",
        "    def _create_risk_colormap(self):\n",
        "        \"\"\"Create colormap from red to yellow to green for heatmaps\"\"\"\n",
        "        return LinearSegmentedColormap.from_list(\n",
        "            'risk_cmap',\n",
        "            [(0.0, self.color_palette['High Risk']),\n",
        "             (0.5, self.color_palette['Medium Risk']),\n",
        "             (1.0, self.color_palette['Low Risk'])],\n",
        "            N=100\n",
        "        )\n",
        "\n",
        "    def _set_plot_parameters(self):\n",
        "        \"\"\"Set global matplotlib parameters for Nature style\"\"\"\n",
        "        plt.rcParams.update({\n",
        "            'axes.titlesize': 9,\n",
        "            'axes.titleweight': 'bold',\n",
        "            'axes.labelsize': 8,\n",
        "            'xtick.labelsize': 7,\n",
        "            'ytick.labelsize': 7,\n",
        "            'legend.fontsize': 7,\n",
        "            'figure.facecolor': self.color_palette['background'],\n",
        "            'axes.facecolor': self.color_palette['background'],\n",
        "            'figure.figsize': (3.5, 2.5),\n",
        "            'axes.grid': False,\n",
        "            'grid.color': self.color_palette['grid'],\n",
        "            'grid.alpha': 0.5,\n",
        "            'axes.linewidth': 0.5,\n",
        "            'xtick.major.width': 0.5,\n",
        "            'ytick.major.width': 0.5,\n",
        "            'lines.linewidth': 1.0,\n",
        "            'lines.markersize': 3,\n",
        "            'savefig.dpi': 300,\n",
        "            'savefig.format': 'pdf',\n",
        "            'savefig.bbox': 'tight',\n",
        "            'savefig.transparent': False\n",
        "        })\n",
        "\n",
        "#########################################\n",
        "# DATA PREPARATION\n",
        "#########################################\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Class to process and prepare data for visualization\"\"\"\n",
        "\n",
        "    def __init__(self, study_data):\n",
        "        \"\"\"\n",
        "        Initialize with study data dictionary containing:\n",
        "        - studies: List of study names\n",
        "        - categories: List of assessment categories\n",
        "        - priority_levels: List of priority levels for each category\n",
        "        - max_points: List of maximum points for each category\n",
        "        - scores: Dictionary of scores for each category\n",
        "        \"\"\"\n",
        "        self.study_data = study_data\n",
        "        self.processed_data = self._process_data()\n",
        "\n",
        "    def _process_data(self):\n",
        "        \"\"\"Process the raw data into a structured format\"\"\"\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(self.study_data['scores'])\n",
        "        df['Study'] = self.study_data['studies']\n",
        "\n",
        "        # Extract risk matrix\n",
        "        risk_matrix = np.array(df[self.study_data['categories']])\n",
        "\n",
        "        # Group categories by priority level\n",
        "        high_priority_indices = [i for i, level in enumerate(self.study_data['priority_levels']) if level == \"High\"]\n",
        "        medium_priority_indices = [i for i, level in enumerate(self.study_data['priority_levels']) if level == \"Medium\"]\n",
        "        standard_priority_indices = [i for i, level in enumerate(self.study_data['priority_levels']) if level == \"Standard\"]\n",
        "\n",
        "        # Calculate scores\n",
        "        high_priority_scores = risk_matrix[:, high_priority_indices].sum(axis=1)\n",
        "        medium_priority_scores = risk_matrix[:, medium_priority_indices].sum(axis=1)\n",
        "        standard_priority_scores = risk_matrix[:, standard_priority_indices].sum(axis=1)\n",
        "        total_scores = risk_matrix.sum(axis=1)\n",
        "\n",
        "        # Determine risk levels based on framework criteria\n",
        "        risk_levels = []\n",
        "        for i in range(len(self.study_data['studies'])):\n",
        "            if (total_scores[i] >= 14 and high_priority_scores[i] >= 6 and medium_priority_scores[i] >= 3):\n",
        "                risk_levels.append(\"Low Risk\")\n",
        "            elif (total_scores[i] >= 9 and high_priority_scores[i] >= 4 and medium_priority_scores[i] >= 2):\n",
        "                risk_levels.append(\"Medium Risk\")\n",
        "            else:\n",
        "                risk_levels.append(\"High Risk\")\n",
        "\n",
        "        # Add calculated values to DataFrame\n",
        "        df[\"High Priority Score\"] = high_priority_scores\n",
        "        df[\"Medium Priority Score\"] = medium_priority_scores\n",
        "        df[\"Standard Priority Score\"] = standard_priority_scores\n",
        "        df[\"Total Score\"] = total_scores\n",
        "        df[\"Risk Level\"] = risk_levels\n",
        "\n",
        "        # Calculate maximum possible scores\n",
        "        max_high_priority = sum([self.study_data['max_points'][i] for i in high_priority_indices])\n",
        "        max_medium_priority = sum([self.study_data['max_points'][i] for i in medium_priority_indices])\n",
        "        max_standard_priority = sum([self.study_data['max_points'][i] for i in standard_priority_indices])\n",
        "        max_total = sum(self.study_data['max_points'])\n",
        "\n",
        "        # Create normalized matrix for visualization\n",
        "        normalized_matrix = np.zeros((len(df), len(self.study_data['categories'])))\n",
        "        for i, cat in enumerate(self.study_data['categories']):\n",
        "            normalized_matrix[:, i] = df[cat].values / self.study_data['max_points'][i]\n",
        "\n",
        "        # Sort studies by total score\n",
        "        df_sorted = df.sort_values(by=\"Total Score\", ascending=False)\n",
        "\n",
        "        # Create normalized matrix for sorted data\n",
        "        sorted_normalized_matrix = np.zeros((len(df_sorted), len(self.study_data['categories'])))\n",
        "        for i, cat in enumerate(self.study_data['categories']):\n",
        "            sorted_normalized_matrix[:, i] = df_sorted[cat].values / self.study_data['max_points'][i]\n",
        "\n",
        "        return {\n",
        "            'df': df,\n",
        "            'df_sorted': df_sorted,\n",
        "            'risk_matrix': risk_matrix,\n",
        "            'normalized_matrix': normalized_matrix,\n",
        "            'sorted_normalized_matrix': sorted_normalized_matrix,\n",
        "            'categories': self.study_data['categories'],\n",
        "            'studies': self.study_data['studies'],\n",
        "            'priority_levels': self.study_data['priority_levels'],\n",
        "            'max_points': self.study_data['max_points'],\n",
        "            'high_priority_indices': high_priority_indices,\n",
        "            'medium_priority_indices': medium_priority_indices,\n",
        "            'standard_priority_indices': standard_priority_indices,\n",
        "            'max_high_priority': max_high_priority,\n",
        "            'max_medium_priority': max_medium_priority,\n",
        "            'max_standard_priority': max_standard_priority,\n",
        "            'max_total': max_total\n",
        "        }\n",
        "\n",
        "#########################################\n",
        "# VISUALIZATION FUNCTIONS\n",
        "#########################################\n",
        "\n",
        "class Visualizer:\n",
        "    \"\"\"Class containing all visualization functions\"\"\"\n",
        "\n",
        "    def __init__(self, style):\n",
        "        self.style = style\n",
        "\n",
        "    def plot_domain_completion(self, data):\n",
        "        \"\"\"Creates stacked bar chart of domain completion rates\"\"\"\n",
        "        plt.figure(figsize=(6.5, 3.5), facecolor=self.style.color_palette['background'])\n",
        "\n",
        "        # Calculate completion percentage for each domain\n",
        "        completion_percent = []\n",
        "        for i, cat in enumerate(data['categories']):\n",
        "            total_points = data['df'][cat].sum()\n",
        "            max_possible_points = data['max_points'][i] * len(data['studies'])\n",
        "            percent = (total_points / max_possible_points) * 100\n",
        "            completion_percent.append(percent)\n",
        "\n",
        "        # Create DataFrame for stacked bar\n",
        "        df_stacked = pd.DataFrame({\n",
        "            'Domain': data['categories'],\n",
        "            'Completion (%)': completion_percent,\n",
        "            'Missing (%)': [100 - p for p in completion_percent],\n",
        "            'Priority': data['priority_levels'],\n",
        "            'Max Points': data['max_points']\n",
        "        })\n",
        "\n",
        "        # Sort by priority level and completion percentage\n",
        "        priority_order = {\"High\": 0, \"Medium\": 1, \"Standard\": 2}\n",
        "        df_stacked['Priority Order'] = df_stacked['Priority'].map(priority_order)\n",
        "        df_stacked = df_stacked.sort_values(['Priority Order', 'Completion (%)'], ascending=[True, False])\n",
        "\n",
        "        # Create stacked bars\n",
        "        plt.barh(df_stacked['Domain'], df_stacked['Completion (%)'],\n",
        "            color=self.style.color_palette['Low Risk'], label='Complete', alpha=0.8, height=0.6)\n",
        "        plt.barh(df_stacked['Domain'], df_stacked['Missing (%)'],\n",
        "            left=df_stacked['Completion (%)'], color=self.style.color_palette['High Risk'],\n",
        "            label='Missing', alpha=0.8, height=0.6)\n",
        "\n",
        "        # Add annotations\n",
        "        for i, (domain, priority, points) in enumerate(zip(df_stacked['Domain'], df_stacked['Priority'], df_stacked['Max Points'])):\n",
        "            plt.text(101, i, f'{priority} ({points}pts)', va='center', fontsize=6)\n",
        "\n",
        "        # Add separator lines between priority groups\n",
        "        priority_groups = df_stacked.groupby('Priority Order')\n",
        "        cumulative_count = 0\n",
        "        for name, group in priority_groups:\n",
        "            if name > 0:  # Don't add a line before the first group\n",
        "                plt.axhline(y=cumulative_count - 0.5, color='black', linestyle='-', alpha=0.3, linewidth=0.5)\n",
        "            cumulative_count += len(group)\n",
        "\n",
        "        # Finalize plot\n",
        "        plt.xlim(0, 120)\n",
        "        plt.xlabel('Percentage of Maximum Possible Points (%)', fontsize=8)\n",
        "        plt.title('Domain Completion Rate by Priority Level', fontsize=9, fontweight='bold')\n",
        "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, fontsize=7)\n",
        "        plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('domain_completion_by_priority.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('domain_completion_by_priority.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_risk_assessment_heatmap(self, data):\n",
        "        \"\"\"Creates traffic light visualization with circles sized by domain max points\"\"\"\n",
        "        # Adjust figure dimensions - narrower width, taller height\n",
        "        combined_fig = plt.figure(figsize=(5, 17), facecolor=self.style.color_palette['background'])\n",
        "\n",
        "        # Update grid proportions with more height\n",
        "        grid = plt.GridSpec(2, 21, height_ratios=[20, 1], hspace=0.4)\n",
        "\n",
        "        # Create subplots with adjusted widths\n",
        "        ax1 = combined_fig.add_subplot(grid[0, :11])  # Main visualization\n",
        "        ax2 = combined_fig.add_subplot(grid[0, 12:17])  # Priority scores\n",
        "        ax3 = combined_fig.add_subplot(grid[0, 19:])  # Total score column\n",
        "        legend_ax = combined_fig.add_subplot(grid[1, :])  # Legend at bottom\n",
        "        legend_ax.axis('off')  # Hide axis for legend\n",
        "\n",
        "        # Significantly increase the y-axis limits to create more space between rows\n",
        "        num_studies = len(data['df_sorted'])\n",
        "        y_padding = 0.8  # Greatly increased padding between rows\n",
        "\n",
        "        # Set up the axes with increased spacing\n",
        "        ax1.set_xlim(-0.5, len(data['categories'])-0.5)\n",
        "        ax1.set_ylim(-0.5 - y_padding, num_studies-0.5 + y_padding)\n",
        "\n",
        "        # Add dotted light grid lines to main visualization\n",
        "        ax1.set_axisbelow(True)\n",
        "        ax1.grid(which='both', linestyle=':', linewidth=0.5, color='#cccccc', alpha=0.7)\n",
        "\n",
        "        # For even more readability - add alternating row shading with increased height\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            if i % 2 == 0:  # Even rows\n",
        "                ax1.axhspan(i-0.5 - y_padding/2, i+0.5 + y_padding/2, color='#f5f5f5', alpha=0.3, zorder=0)\n",
        "\n",
        "        # Adjust circle size - INCREASED from previous version\n",
        "        base_size = 130  # Increased from 110 to make circles slightly bigger\n",
        "\n",
        "        # Calculate circle sizes based on maximum points\n",
        "        circle_sizes = {}\n",
        "        for i, max_p in enumerate(data['max_points']):\n",
        "            if max_p == 2:\n",
        "                circle_sizes[i] = base_size * 2  # 2 points get base size * 2\n",
        "            else:  # max_p == 3\n",
        "                circle_sizes[i] = base_size * 3  # 3 points get base size * 3\n",
        "\n",
        "        # Plot circles with size based on domain maximum points (consistent across columns)\n",
        "        for i, study_idx in enumerate(range(len(data['df_sorted']))):\n",
        "            for j, category_idx in enumerate(range(len(data['categories']))):\n",
        "                # Get the normalized value for color\n",
        "                normalized_value = data['sorted_normalized_matrix'][study_idx, category_idx]\n",
        "                # Get color from colormap\n",
        "                color = self.style.risk_cmap(normalized_value)\n",
        "\n",
        "                # Use pre-calculated size for this domain\n",
        "                circle_size = circle_sizes[category_idx]\n",
        "\n",
        "                # Create a circle using scatter plot\n",
        "                ax1.scatter(j, i, s=circle_size, c=[color], alpha=0.8,\n",
        "                          edgecolors='white', linewidths=0.5, zorder=2)\n",
        "\n",
        "        # Create y-axis labels (study names without risk level abbreviation)\n",
        "        y_labels = data['df_sorted']['Study'].values\n",
        "\n",
        "        # Set y-axis labels with increased font size\n",
        "        ax1.set_yticks(range(len(y_labels)))\n",
        "        ax1.set_yticklabels(y_labels, fontsize=8, rotation=0)\n",
        "        ax1.tick_params(axis='y', pad=25)\n",
        "\n",
        "        # Set x-axis labels horizontally with full category names\n",
        "        ax1.set_xticks(range(len(data['categories'])))\n",
        "\n",
        "        # Create x-labels - now vertical and on one line with proper point notation\n",
        "        x_labels = []\n",
        "        for cat, max_p in zip(data['categories'], data['max_points']):\n",
        "            # Simplified label format - single line, no breaks\n",
        "            if cat == \"Error Analysis\":\n",
        "                label = \"Error Analysis\"\n",
        "            elif cat == \"Fairness Assessment\":\n",
        "                label = \"Fairness Assessment\"\n",
        "            elif cat == \"Dataset Availability\":\n",
        "                label = \"Dataset Availability\"\n",
        "            elif cat == \"External Validation\":\n",
        "                label = \"External Validation\"\n",
        "            elif cat == \"Annotation Guidelines\":\n",
        "                label = \"Annotation Guidelines\"\n",
        "            elif cat == \"Code/Prompt Availability\":\n",
        "                label = \"Code/Prompt Availability\"\n",
        "            elif cat == \"Medical Condition Specificity\":\n",
        "                label = \"Medical Condition\"\n",
        "            else:\n",
        "                label = cat\n",
        "\n",
        "            # Add points notation\n",
        "            x_labels.append(f\"{label} ({max_p} pts)\")\n",
        "\n",
        "        # Set vertical x-axis labels with decreased font size\n",
        "        ax1.set_xticklabels(x_labels, rotation=90, ha='center', va='top', fontsize=8, fontweight='bold')\n",
        "        ax1.tick_params(axis='x', pad=7)\n",
        "        ax1.set_title('Domain Scores by Study', fontsize=9, fontweight='bold', pad=15)\n",
        "\n",
        "        # Set up the axes for the priority scores visualization with increased spacing\n",
        "        ax2.set_xlim(-0.5, 3-0.5)  # Now only 3 columns (High, Medium, Standard)\n",
        "        ax2.set_ylim(-0.5 - y_padding, num_studies-0.5 + y_padding)\n",
        "\n",
        "        # Add dotted light grid lines to priority scores visualization\n",
        "        ax2.set_axisbelow(True)\n",
        "        ax2.grid(which='both', linestyle=':', linewidth=0.5, color='#cccccc', alpha=0.7)\n",
        "\n",
        "        # Set up the axes for the total score visualization\n",
        "        ax3.set_xlim(-0.5, 0.5)  # Just one column\n",
        "        ax3.set_ylim(-0.5 - y_padding, num_studies-0.5 + y_padding)\n",
        "\n",
        "        # Add dotted light grid lines to total score visualization\n",
        "        ax3.set_axisbelow(True)\n",
        "        ax3.grid(which='both', linestyle=':', linewidth=0.5, color='#cccccc', alpha=0.7)\n",
        "\n",
        "        # Add shading to total score column\n",
        "        ax3.axvspan(-0.5, 0.5, color='#e6e6e6', alpha=0.7, zorder=0)\n",
        "\n",
        "        # For consistency - add same alternating row shading to both summary sections with increased height\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            if i % 2 == 0:  # Even rows\n",
        "                ax2.axhspan(i-0.5 - y_padding/2, i+0.5 + y_padding/2, color='#f5f5f5', alpha=0.3, zorder=0)\n",
        "                ax3.axhspan(i-0.5 - y_padding/2, i+0.5 + y_padding/2, color='#f5f5f5', alpha=0.3, zorder=0)\n",
        "\n",
        "        # Prepare data for summary visualizations\n",
        "        summary_data_priorities = np.zeros((len(data['df_sorted']), 3))\n",
        "        summary_data_priorities[:, 0] = data['df_sorted']['High Priority Score'].values / data['max_high_priority']\n",
        "        summary_data_priorities[:, 1] = data['df_sorted']['Medium Priority Score'].values / data['max_medium_priority']\n",
        "        summary_data_priorities[:, 2] = data['df_sorted']['Standard Priority Score'].values / data['max_standard_priority']\n",
        "\n",
        "        summary_data_total = np.zeros((len(data['df_sorted']), 1))\n",
        "        summary_data_total[:, 0] = data['df_sorted']['Total Score'].values / data['max_total']\n",
        "\n",
        "        # Use a larger size for all priority section circles\n",
        "        priority_circle_size = 290\n",
        "        total_circle_size = 310  # Slightly larger for total score\n",
        "\n",
        "        # Plot circles for priority scores\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            for j in range(3):  # 3 columns: High, Medium, Standard\n",
        "                normalized_value = summary_data_priorities[i, j]\n",
        "                color = self.style.risk_cmap(normalized_value)\n",
        "\n",
        "                # Create a circle using scatter plot\n",
        "                ax2.scatter(j, i, s=priority_circle_size, c=[color], alpha=0.8,\n",
        "                           edgecolors='white', linewidths=0.5, zorder=2)\n",
        "\n",
        "                # Add score text inside each circle\n",
        "                if j == 0:\n",
        "                    score = data['df_sorted']['High Priority Score'].iloc[i]\n",
        "                elif j == 1:\n",
        "                    score = data['df_sorted']['Medium Priority Score'].iloc[i]\n",
        "                else:  # j == 2\n",
        "                    score = data['df_sorted']['Standard Priority Score'].iloc[i]\n",
        "\n",
        "                ax2.text(j, i, str(int(score)), ha='center', va='center', fontsize=6,\n",
        "                        color='white', fontweight='bold', zorder=3)  # Text on top\n",
        "\n",
        "        # Plot circles for total score\n",
        "        for i in range(len(data['df_sorted'])):\n",
        "            normalized_value = summary_data_total[i, 0]\n",
        "            color = self.style.risk_cmap(normalized_value)\n",
        "\n",
        "            # Create a circle using scatter plot\n",
        "            ax3.scatter(0, i, s=total_circle_size, c=[color], alpha=0.8,\n",
        "                       edgecolors='white', linewidths=0.5, zorder=2)\n",
        "\n",
        "            # Add score text inside each circle\n",
        "            score = data['df_sorted']['Total Score'].iloc[i]\n",
        "            ax3.text(0, i, str(int(score)), ha='center', va='center', fontsize=6,\n",
        "                    color='white', fontweight='bold', zorder=3)  # Text on top\n",
        "\n",
        "        # Make priority scores x-axis labels vertical with decreased font\n",
        "        ax2.set_xticks(range(3))\n",
        "        ax2.set_xticklabels([\n",
        "            f'High Priority ({data[\"max_high_priority\"]})',\n",
        "            f'Medium Priority ({data[\"max_medium_priority\"]})',\n",
        "            f'Standard Priority ({data[\"max_standard_priority\"]})'\n",
        "        ], rotation=90, ha='center', va='top', fontsize=8, fontweight='bold')\n",
        "        ax2.tick_params(axis='x', pad=7)\n",
        "\n",
        "        # Set up total score x-axis label\n",
        "        ax3.set_xticks([0])\n",
        "        ax3.set_xticklabels([f'Total Score ({data[\"max_total\"]})'],\n",
        "                             rotation=90, ha='center', va='top', fontsize=8, fontweight='bold')\n",
        "        ax3.tick_params(axis='x', pad=7)\n",
        "\n",
        "        # Remove y-axis labels for summary sections\n",
        "        ax2.set_yticklabels(['' for _ in range(len(data['df_sorted']))])\n",
        "        ax3.set_yticklabels(['' for _ in range(len(data['df_sorted']))])\n",
        "\n",
        "        # Set titles for summary sections\n",
        "        ax2.set_title('Priority Scores', fontsize=9, fontweight='bold', pad=15)\n",
        "        ax3.set_title('Overall Score', fontsize=9, fontweight='bold', pad=15)\n",
        "\n",
        "        # Create legend for risk levels and circle sizes\n",
        "        from matplotlib.lines import Line2D\n",
        "        risk_legend_elements = [\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=self.style.color_palette['Low Risk'],\n",
        "                  markersize=12, label='Low Risk', markeredgecolor='white', markeredgewidth=0.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=self.style.color_palette['Medium Risk'],\n",
        "                  markersize=12, label='Medium Risk', markeredgecolor='white', markeredgewidth=0.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=self.style.color_palette['High Risk'],\n",
        "                  markersize=12, label='High Risk', markeredgecolor='white', markeredgewidth=0.5)\n",
        "        ]\n",
        "\n",
        "        # Create size legend only for the domain section\n",
        "        size_legend_elements = [\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor='#999999',\n",
        "                   markersize=np.sqrt(base_size * 2)/2.5, label='2 points',\n",
        "                   markeredgecolor='white', markeredgewidth=0.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor='#999999',\n",
        "                   markersize=np.sqrt(base_size * 3)/2.5, label='3 points',\n",
        "                   markeredgecolor='white', markeredgewidth=0.5)\n",
        "        ]\n",
        "\n",
        "        # Create the combined legend\n",
        "        all_legend_elements = risk_legend_elements + size_legend_elements\n",
        "        all_legend_labels = ['Low Risk', 'Medium Risk', 'High Risk', '2 points', '3 points']\n",
        "\n",
        "        # Add the combined legend with larger font\n",
        "        legend = legend_ax.legend(all_legend_elements, all_legend_labels,\n",
        "                               loc='center', fontsize=8, frameon=True,\n",
        "                               ncol=5, columnspacing=1.0,\n",
        "                               bbox_to_anchor=(0.5, 0.5))\n",
        "\n",
        "        # Move the title a bit closer to the plot\n",
        "        combined_fig.suptitle('Risk of Bias Assessment for LLMs Identifying SDoH',\n",
        "                             fontsize=12, fontweight='bold', y=0.92)\n",
        "\n",
        "        # Move criteria text a bit closer to the plot\n",
        "        criteria_text = \"\"\"Risk Criteria: Low: ≥14 total AND ≥6 High AND ≥3 Medium points | Medium: ≥9 total AND ≥4 High AND ≥2 Medium points | High: Below thresholds\"\"\"\n",
        "        combined_fig.text(0.5, 0.1, criteria_text, ha='center', fontsize=7,\n",
        "                        bbox={'facecolor': 'lightgrey', 'alpha': 0.5, 'pad': 5})\n",
        "\n",
        "        # Adjust layout to better accommodate all elements\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "\n",
        "        plt.savefig('risk_assessment_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('risk_assessment_heatmap.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_risk_distribution(self, data):\n",
        "        \"\"\"Creates bar chart of risk level distribution\"\"\"\n",
        "        # Count studies in each risk category\n",
        "        risk_counts = data['df']['Risk Level'].value_counts()\n",
        "\n",
        "        # Create a complete DataFrame with all risk levels\n",
        "        all_risk_levels = ['High Risk', 'Medium Risk', 'Low Risk']\n",
        "        complete_risk_counts = pd.Series(0, index=all_risk_levels)\n",
        "\n",
        "        # Update with actual counts\n",
        "        for level in risk_counts.index:\n",
        "            complete_risk_counts[level] = risk_counts[level]\n",
        "\n",
        "        # Sort in desired order\n",
        "        complete_risk_counts = complete_risk_counts.reindex(['High Risk', 'Medium Risk', 'Low Risk'])\n",
        "\n",
        "        plt.figure(figsize=(3.5, 2.5), facecolor=self.style.color_palette['background'])\n",
        "        bars = plt.bar(range(len(all_risk_levels)), complete_risk_counts.values,\n",
        "                       color=[self.style.color_palette[level] for level in all_risk_levels], width=0.6)\n",
        "\n",
        "        # Add count and percentage labels\n",
        "        for i, v in enumerate(complete_risk_counts.values):\n",
        "            if v > 0:\n",
        "                plt.text(i, v + 0.3, str(int(v)), ha='center', fontweight='bold', fontsize=7)\n",
        "                percentage = (v / len(data['studies'])) * 100\n",
        "                plt.text(i, v/2, f\"{percentage:.1f}%\", ha='center', va='center',\n",
        "                         color='white', fontweight='bold', fontsize=7)\n",
        "\n",
        "        plt.ylabel('Number of Studies', fontsize=8)\n",
        "        plt.title('Distribution of Studies by Risk Level', fontsize=9, fontweight='bold')\n",
        "        plt.ylim(0, max(complete_risk_counts.values) * 1.2 if max(complete_risk_counts.values) > 0 else 1)\n",
        "        plt.xticks(range(len(all_risk_levels)), ['High', 'Medium', 'Low'], fontsize=7)\n",
        "        plt.yticks(fontsize=7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('risk_level_distribution.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('risk_level_distribution.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_risk_by_year(self, data):\n",
        "        \"\"\"Creates stacked bar chart of risk levels by publication year\"\"\"\n",
        "        # Extract publication years from study names\n",
        "        years = []\n",
        "        for study in data['studies']:\n",
        "            year_part = study.split()[-1]\n",
        "            numeric_year = ''.join(c for c in year_part if c.isdigit())\n",
        "            years.append(int(numeric_year))\n",
        "\n",
        "        unique_years = sorted(set(years))\n",
        "\n",
        "        # Calculate risk level distribution by year\n",
        "        year_risk_data = {}\n",
        "        for year in unique_years:\n",
        "            year_indices = [i for i, y in enumerate(years) if y == year]\n",
        "            year_risk_levels = [data['df']['Risk Level'].iloc[i] for i in year_indices]\n",
        "            year_risk_counts = {'High Risk': 0, 'Medium Risk': 0, 'Low Risk': 0}\n",
        "            for risk in year_risk_levels:\n",
        "                year_risk_counts[risk] += 1\n",
        "            year_risk_data[year] = year_risk_counts\n",
        "\n",
        "        # Prepare data for stacked bar chart\n",
        "        years_for_plot = []\n",
        "        high_risk_counts = []\n",
        "        medium_risk_counts = []\n",
        "        low_risk_counts = []\n",
        "        study_counts = []\n",
        "\n",
        "        for year in unique_years:\n",
        "            years_for_plot.append(year)\n",
        "            high_risk_counts.append(year_risk_data[year]['High Risk'])\n",
        "            medium_risk_counts.append(year_risk_data[year]['Medium Risk'])\n",
        "            low_risk_counts.append(year_risk_data[year]['Low Risk'])\n",
        "            study_counts.append(sum(year_risk_data[year].values()))\n",
        "\n",
        "        # Create stacked bar chart\n",
        "        plt.figure(figsize=(4.5, 2.5), facecolor=self.style.color_palette['background'])\n",
        "        width = 0.6\n",
        "\n",
        "        p1 = plt.bar(years_for_plot, low_risk_counts, width, color=self.style.color_palette['Low Risk'], label='Low')\n",
        "        p2 = plt.bar(years_for_plot, medium_risk_counts, width,\n",
        "                     bottom=low_risk_counts, color=self.style.color_palette['Medium Risk'], label='Medium')\n",
        "        p3 = plt.bar(years_for_plot, high_risk_counts, width,\n",
        "                     bottom=[i+j for i,j in zip(low_risk_counts, medium_risk_counts)],\n",
        "                     color=self.style.color_palette['High Risk'], label='High')\n",
        "\n",
        "        # Add study count annotations\n",
        "        for i, count in enumerate(study_counts):\n",
        "            plt.text(years_for_plot[i], count + 0.2, f\"n={count}\", ha='center', fontsize=6)\n",
        "\n",
        "        plt.xlabel('Publication Year', fontsize=8)\n",
        "        plt.ylabel('Number of Studies', fontsize=8)\n",
        "        plt.title('Risk Levels by Publication Year', fontsize=9, fontweight='bold')\n",
        "        plt.xticks(years_for_plot, fontsize=7)\n",
        "        plt.yticks(fontsize=7)\n",
        "        plt.legend(fontsize=6, title=\"Risk\", title_fontsize=7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('risk_distribution_by_year.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('risk_distribution_by_year.pdf', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def plot_domain_correlation(self, data):\n",
        "        \"\"\"Creates correlation heatmap between risk domains with complete, non-trimmed labels\"\"\"\n",
        "        # Normalize the scores for correlation calculation\n",
        "        normalized_scores = np.zeros_like(data['risk_matrix'], dtype=float)\n",
        "        for i, max_p in enumerate(data['max_points']):\n",
        "            normalized_scores[:, i] = data['risk_matrix'][:, i] / max_p\n",
        "\n",
        "        # Calculate correlation\n",
        "        corr_matrix = np.corrcoef(normalized_scores.T)\n",
        "        corr_df = pd.DataFrame(corr_matrix, index=data['categories'], columns=data['categories'])\n",
        "\n",
        "        # Create mask for lower triangle (including diagonal)\n",
        "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
        "\n",
        "        # Use the original full category names\n",
        "        category_labels = data['categories']\n",
        "\n",
        "        # Create a much larger figure to accommodate full-length labels\n",
        "        plt.figure(figsize=(11, 9), facecolor=self.style.color_palette['background'])\n",
        "\n",
        "        # Create custom color map\n",
        "        custom_cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "        # Create the heatmap with full original labels\n",
        "        heatmap = sns.heatmap(\n",
        "            corr_df,\n",
        "            annot=True,\n",
        "            cmap=custom_cmap,\n",
        "            vmin=-1,\n",
        "            vmax=1,\n",
        "            center=0,\n",
        "            linewidths=0.5,\n",
        "            fmt='.2f',\n",
        "            annot_kws={'size': 14},\n",
        "            mask=mask,\n",
        "            xticklabels=category_labels,\n",
        "            yticklabels=category_labels,\n",
        "            cbar_kws={'label': 'Correlation Coefficient'}\n",
        "        )\n",
        "\n",
        "        # Set x-axis labels with significant rotation and proper positioning\n",
        "        plt.xticks(rotation=45, ha='right', fontweight='bold', fontsize=12)\n",
        "\n",
        "        # Set y-axis labels\n",
        "        plt.yticks(rotation=0, va='center', fontweight='bold', fontsize=12)\n",
        "\n",
        "        # Adjust colorbar label\n",
        "        cbar = heatmap.collections[0].colorbar\n",
        "        cbar.ax.tick_params(labelsize=9)\n",
        "        cbar.set_label('Correlation Coefficient', fontsize=14)\n",
        "\n",
        "        # Add title with adjusted position\n",
        "        plt.title('Correlation Between Risk Domains', fontsize=14, fontweight='bold', pad=10)\n",
        "\n",
        "        # Add significant margins to ensure labels aren't cut off\n",
        "        plt.subplots_adjust(bottom=0.35, left=0.25)\n",
        "\n",
        "        # Save with extra padding to ensure no labels are trimmed\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('domain_correlation.png', dpi=300, bbox_inches='tight', pad_inches=0.5)\n",
        "        plt.savefig('domain_correlation.pdf', bbox_inches='tight', pad_inches=0.5)\n",
        "        plt.close()\n",
        "\n",
        "    def plot_score_scatter(self, data):\n",
        "        \"\"\"Creates scatter plot with clear labels for nodes with special handling for problematic areas\"\"\"\n",
        "        # Import necessary modules\n",
        "        from matplotlib.lines import Line2D\n",
        "        import matplotlib.patheffects as path_effects\n",
        "        import numpy as np\n",
        "\n",
        "        # Extract data\n",
        "        df = data['df'].copy()\n",
        "\n",
        "        # Find overlapping points\n",
        "        coordinate_counts = df.groupby(['High Priority Score', 'Total Score']).size().reset_index(name='count')\n",
        "\n",
        "        # Create figure\n",
        "        plt.figure(figsize=(12.0, 10.0), facecolor='white')\n",
        "\n",
        "        # Define color scheme\n",
        "        enhanced_colors = {\n",
        "            'Low Risk': '#1a9850',        # Green\n",
        "            'Medium Risk': '#fdae61',     # Orange/Yellow\n",
        "            'High Risk': '#d73027',       # Red\n",
        "            'Medium-High': '#f4a582',     # Lighter orange\n",
        "            'High-Medium': '#d6604d',     # Lighter red\n",
        "            'background': '#f8f9fa'       # Light gray background\n",
        "        }\n",
        "\n",
        "        # Set plot boundaries\n",
        "        x_min = -1.0\n",
        "        y_min = -1.0\n",
        "        x_max = data['max_high_priority'] + 1.0\n",
        "        y_max = data['max_total'] + 2.0\n",
        "\n",
        "        # Create gradient backgrounds for risk zones\n",
        "        from matplotlib.colors import LinearSegmentedColormap\n",
        "        high_risk_cmap = LinearSegmentedColormap.from_list('high_risk', ['#ffebee', '#ffcdd2'])\n",
        "        medium_risk_cmap = LinearSegmentedColormap.from_list('medium_risk', ['#fff8e1', '#ffecb3'])\n",
        "        low_risk_cmap = LinearSegmentedColormap.from_list('low_risk', ['#e8f5e9', '#c8e6c9'])\n",
        "\n",
        "        # Create background grid\n",
        "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
        "        high_risk_mask = ((xx < 4) | ((xx < 6) & (yy < 9)))\n",
        "        medium_risk_mask = ((xx >= 4) & (xx < 6) & (yy >= 9) & (yy < 14)) | ((xx >= 6) & (yy < 14))\n",
        "        low_risk_mask = (xx >= 6) & (yy >= 14)\n",
        "\n",
        "        # Plot risk zone backgrounds\n",
        "        plt.imshow(np.zeros_like(xx), extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0, aspect='auto')\n",
        "        plt.imshow(high_risk_mask, extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0.15, aspect='auto', cmap=high_risk_cmap, origin='lower')\n",
        "        plt.imshow(medium_risk_mask, extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0.15, aspect='auto', cmap=medium_risk_cmap, origin='lower')\n",
        "        plt.imshow(low_risk_mask, extent=[x_min, x_max, y_min, y_max],\n",
        "                  alpha=0.15, aspect='auto', cmap=low_risk_cmap, origin='lower')\n",
        "\n",
        "        # Add subtle grid\n",
        "        plt.grid(True, linestyle='-', linewidth=0.6, alpha=0.15, color='#bdbdbd')\n",
        "\n",
        "        # Calculate risk levels\n",
        "        df['Corrected Risk Level'] = 'High Risk'  # Default\n",
        "\n",
        "        # Medium risk: ≥9 total AND ≥4 High\n",
        "        medium_mask = (df['Total Score'] >= 9) & (df['High Priority Score'] >= 4)\n",
        "        df.loc[medium_mask, 'Corrected Risk Level'] = 'Medium Risk'\n",
        "\n",
        "        # Low risk: ≥14 total AND ≥6 High\n",
        "        low_mask = (df['Total Score'] >= 14) & (df['High Priority Score'] >= 6)\n",
        "        df.loc[low_mask, 'Corrected Risk Level'] = 'Low Risk'\n",
        "\n",
        "        # Add nuanced risk levels for boundary areas\n",
        "        high_medium_mask = (df['High Priority Score'] >= 4) & (df['Total Score'] < 9)\n",
        "        df.loc[high_medium_mask, 'Corrected Risk Level'] = 'High-Medium'\n",
        "\n",
        "        medium_high_mask = (df['Total Score'] >= 9) & (df['High Priority Score'] < 4)\n",
        "        df.loc[medium_high_mask, 'Corrected Risk Level'] = 'Medium-High'\n",
        "\n",
        "        # Create simplified labels\n",
        "        simple_labels = []\n",
        "        for study in df['Study']:\n",
        "            parts = study.split()\n",
        "            if len(parts) > 1:\n",
        "                name = parts[0]\n",
        "                year = parts[-1]\n",
        "                simple_labels.append(f\"{name} {year}\")\n",
        "            else:\n",
        "                simple_labels.append(study)\n",
        "        df['Simple_Label'] = simple_labels\n",
        "\n",
        "        # STEP 1: Define known problematic coordinates\n",
        "        problem_areas = [\n",
        "            (6, 10),  # The top node in the cluster\n",
        "            (6, 8),   # The bottom node in the cluster\n",
        "        ]\n",
        "\n",
        "        # Define specific placement strategies for these problem areas\n",
        "        specific_placement = {\n",
        "            (6, 10): {\n",
        "                'direction': 'right',  # Place labels to the right\n",
        "                'offset_x': 0.9,       # Use larger offset\n",
        "                'offset_y': 0.3,       # Move slightly up\n",
        "                'ha': 'left',\n",
        "                'va': 'center'\n",
        "            },\n",
        "            (6, 8): {\n",
        "                'direction': 'left',   # Place labels to the left\n",
        "                'offset_x': -0.9,      # Use larger offset\n",
        "                'offset_y': -0.3,      # Move slightly down\n",
        "                'ha': 'right',\n",
        "                'va': 'center'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # STEP 2: Plot nodes and identify special cases\n",
        "        nodes = {}\n",
        "        all_node_positions = []\n",
        "\n",
        "        for _, row in coordinate_counts.iterrows():\n",
        "            x = row['High Priority Score']\n",
        "            y = row['Total Score']\n",
        "            count = row['count']\n",
        "            all_node_positions.append((x, y))\n",
        "\n",
        "            # Get risk level for this position\n",
        "            cluster_df = df[(df['High Priority Score'] == x) & (df['Total Score'] == y)]\n",
        "            risk_level = cluster_df['Corrected Risk Level'].iloc[0]\n",
        "            color = enhanced_colors[risk_level]\n",
        "\n",
        "            # Create scatter point\n",
        "            node_size = 750\n",
        "            scatter = plt.scatter(x, y, c=[color], alpha=1.0, s=node_size,\n",
        "                              edgecolors='black', linewidths=2.0, zorder=10)\n",
        "\n",
        "            # Store node information - check if this is a known problem area\n",
        "            is_problem = (x, y) in problem_areas\n",
        "            nodes[(x, y)] = {\n",
        "                'x': x,\n",
        "                'y': y,\n",
        "                'color': color,\n",
        "                'count': count,\n",
        "                'risk_level': risk_level,\n",
        "                'radius': 0.35,  # Approximate node radius in data units\n",
        "                'is_problem': is_problem,\n",
        "                'specific_placement': specific_placement.get((x, y))\n",
        "            }\n",
        "\n",
        "            # Add count label for clusters\n",
        "            if count > 1:\n",
        "                plt.text(x, y, str(count), ha='center', va='center',\n",
        "                      color='white', fontsize=10, fontweight='bold', zorder=15)\n",
        "\n",
        "        # STEP 3: Enhanced labeling with different strategies for regular vs. problem areas\n",
        "\n",
        "        # Group studies by coordinates\n",
        "        grouped_studies = df.groupby(['High Priority Score', 'Total Score'])\n",
        "\n",
        "        # Track label positions to avoid overlaps\n",
        "        placed_labels = []\n",
        "\n",
        "        # Process nodes in order of priority (problem areas first)\n",
        "        coords = list(nodes.keys())\n",
        "        # Sort by whether they're problem areas (True comes before False)\n",
        "        coords.sort(key=lambda c: not nodes[c]['is_problem'])\n",
        "\n",
        "        # Process each node\n",
        "        for coord in coords:\n",
        "            x, y = coord\n",
        "            node = nodes[coord]\n",
        "            group = grouped_studies.get_group(coord)\n",
        "            studies = group['Simple_Label'].tolist()\n",
        "\n",
        "            # Choose positioning strategy based on whether this is a problem area\n",
        "            if node['is_problem']:\n",
        "                # Use specific placement strategy for this problem area\n",
        "                placement = node['specific_placement']\n",
        "\n",
        "                # For multiple labels, adjust vertical spacing\n",
        "                label_spacing = 0.5  # Vertical space between labels\n",
        "\n",
        "                # Process each study at this node\n",
        "                for i, study in enumerate(studies):\n",
        "                    # Get study's risk level\n",
        "                    study_row = group[group['Simple_Label'] == study].iloc[0]\n",
        "                    risk_level = study_row['Corrected Risk Level']\n",
        "                    color = enhanced_colors[risk_level]\n",
        "\n",
        "                    # Calculate position with vertical stacking if multiple labels\n",
        "                    if placement['direction'] == 'right':\n",
        "                        label_x = x + placement['offset_x']\n",
        "                        # Stack vertically if multiple studies\n",
        "                        if len(studies) > 1:\n",
        "                            label_y = y + placement['offset_y'] + (i - (len(studies)-1)/2) * label_spacing\n",
        "                        else:\n",
        "                            label_y = y + placement['offset_y']\n",
        "                    else:  # 'left'\n",
        "                        label_x = x + placement['offset_x']\n",
        "                        # Stack vertically if multiple studies\n",
        "                        if len(studies) > 1:\n",
        "                            label_y = y + placement['offset_y'] + (i - (len(studies)-1)/2) * label_spacing\n",
        "                        else:\n",
        "                            label_y = y + placement['offset_y']\n",
        "\n",
        "                    # Keep within bounds\n",
        "                    label_x = max(x_min + 0.2, min(label_x, x_max - 0.2))\n",
        "                    label_y = max(y_min + 0.2, min(label_y, y_max - 0.2))\n",
        "\n",
        "                    # Calculate connector start point at node edge\n",
        "                    angle = np.arctan2(label_y - y, label_x - x)\n",
        "                    start_x = x + node['radius'] * np.cos(angle)\n",
        "                    start_y = y + node['radius'] * np.sin(angle)\n",
        "\n",
        "                    # Draw connector line\n",
        "                    plt.plot([start_x, label_x], [start_y, label_y],\n",
        "                          color='black', linewidth=0.4, alpha=0.7, zorder=5)\n",
        "\n",
        "                    # Add label text with outline\n",
        "                    plt.text(label_x, label_y, study,\n",
        "                          fontsize=7,\n",
        "                          fontweight='bold',\n",
        "                          color=color,\n",
        "                          ha=placement['ha'], va=placement['va'],\n",
        "                          zorder=15,\n",
        "                          path_effects=[path_effects.withStroke(linewidth=0.1, foreground='black')])\n",
        "\n",
        "                    # Store this label position to check for future overlaps\n",
        "                    placed_labels.append((label_x, label_y, study))\n",
        "            else:\n",
        "                # Standard placement strategy for regular nodes\n",
        "                for i, study in enumerate(studies):\n",
        "                    # Calculate position based on chart position and cluster size\n",
        "                    if len(studies) == 1:\n",
        "                        # Single study - place based on chart position\n",
        "                        chart_x_ratio = (x - x_min) / (x_max - x_min)\n",
        "                        chart_y_ratio = (y - y_min) / (y_max - y_min)\n",
        "\n",
        "                        # Choose offset direction based on quadrant\n",
        "                        if chart_x_ratio < 0.3:\n",
        "                            offset_x = 0.6\n",
        "                            offset_y = 0.0\n",
        "                            ha = 'left'\n",
        "                            va = 'center'\n",
        "                        elif chart_x_ratio > 0.7:\n",
        "                            offset_x = -0.6\n",
        "                            offset_y = 0.0\n",
        "                            ha = 'right'\n",
        "                            va = 'center'\n",
        "                        elif chart_y_ratio < 0.3:\n",
        "                            offset_x = 0.0\n",
        "                            offset_y = 0.6\n",
        "                            ha = 'center'\n",
        "                            va = 'bottom'\n",
        "                        elif chart_y_ratio > 0.7:\n",
        "                            offset_x = 0.0\n",
        "                            offset_y = -0.6\n",
        "                            ha = 'center'\n",
        "                            va = 'top'\n",
        "                        else:\n",
        "                            offset_x = 0.6\n",
        "                            offset_y = 0.6\n",
        "                            ha = 'left'\n",
        "                            va = 'bottom'\n",
        "                    else:\n",
        "                        # Multiple studies - use radial arrangement\n",
        "                        angle = 2 * np.pi * i / len(studies)\n",
        "                        offset_x = 0.6 * np.cos(angle)\n",
        "                        offset_y = 0.6 * np.sin(angle)\n",
        "\n",
        "                        if -np.pi/4 <= angle < np.pi/4:\n",
        "                            ha = 'left'\n",
        "                            va = 'center'\n",
        "                        elif np.pi/4 <= angle < 3*np.pi/4:\n",
        "                            ha = 'center'\n",
        "                            va = 'bottom'\n",
        "                        elif -3*np.pi/4 <= angle < -np.pi/4:\n",
        "                            ha = 'center'\n",
        "                            va = 'top'\n",
        "                        else:\n",
        "                            ha = 'right'\n",
        "                            va = 'center'\n",
        "\n",
        "                    # Calculate label position\n",
        "                    label_x = x + offset_x\n",
        "                    label_y = y + offset_y\n",
        "\n",
        "                    # Ensure within bounds\n",
        "                    label_x = max(x_min + 0.2, min(label_x, x_max - 0.2))\n",
        "                    label_y = max(y_min + 0.2, min(label_y, y_max - 0.2))\n",
        "\n",
        "                    # Check for overlaps with already placed labels\n",
        "                    overlap = True\n",
        "                    attempts = 0\n",
        "                    orig_x, orig_y = label_x, label_y\n",
        "\n",
        "                    # Try to find non-overlapping position by increasing offset\n",
        "                    while overlap and attempts < 5:\n",
        "                        overlap = False\n",
        "                        for ex_x, ex_y, _ in placed_labels:\n",
        "                            # Check if too close to existing label\n",
        "                            dist = np.sqrt((label_x - ex_x)**2 + (label_y - ex_y)**2)\n",
        "                            if dist < 0.6:  # Minimum distance between labels\n",
        "                                overlap = True\n",
        "                                break\n",
        "\n",
        "                        if overlap:\n",
        "                            # Increase offset in same direction\n",
        "                            attempts += 1\n",
        "                            scale = 1 + 0.2 * attempts  # Increase by 20% each attempt\n",
        "                            label_x = x + offset_x * scale\n",
        "                            label_y = y + offset_y * scale\n",
        "\n",
        "                            # Ensure within bounds\n",
        "                            label_x = max(x_min + 0.2, min(label_x, x_max - 0.2))\n",
        "                            label_y = max(y_min + 0.2, min(label_y, y_max - 0.2))\n",
        "\n",
        "                    # Get study's risk level from its row\n",
        "                    study_row = group[group['Simple_Label'] == study].iloc[0]\n",
        "                    risk_level = study_row['Corrected Risk Level']\n",
        "                    color = enhanced_colors[risk_level]\n",
        "\n",
        "                    # Calculate connector start point at node edge\n",
        "                    angle = np.arctan2(label_y - y, label_x - x)\n",
        "                    start_x = x + node['radius'] * np.cos(angle)\n",
        "                    start_y = y + node['radius'] * np.sin(angle)\n",
        "\n",
        "                    # Draw connector line\n",
        "                    plt.plot([start_x, label_x], [start_y, label_y],\n",
        "                          color='black', linewidth=0.4, alpha=0.7, zorder=5)\n",
        "\n",
        "                    # Add label text with outline\n",
        "                    plt.text(label_x, label_y, study,\n",
        "                          fontsize=7,\n",
        "                          fontweight='bold',\n",
        "                          color=color,\n",
        "                          ha=ha, va=va,\n",
        "                          zorder=15,\n",
        "                          path_effects=[path_effects.withStroke(linewidth=0.1, foreground='black')])\n",
        "\n",
        "                    # Store this label position\n",
        "                    placed_labels.append((label_x, label_y, study))\n",
        "\n",
        "        # Add threshold lines\n",
        "        plt.axhline(y=14, color=enhanced_colors['Low Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "        plt.axhline(y=9, color=enhanced_colors['Medium Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "        plt.axvline(x=6, color=enhanced_colors['Low Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "        plt.axvline(x=4, color=enhanced_colors['Medium Risk'], linestyle='--',\n",
        "                  alpha=0.6, linewidth=1.4)\n",
        "\n",
        "        # Add risk region labels\n",
        "        text_effects = [\n",
        "            path_effects.Stroke(linewidth=3, foreground='white', alpha=0.8),\n",
        "            path_effects.Normal()\n",
        "        ]\n",
        "\n",
        "        # Risk zone labels\n",
        "        low_text = plt.text(9.2, 18, \"Low Risk\", fontsize=28, ha='center', va='center',\n",
        "                          color=enhanced_colors['Low Risk'], fontweight='bold', alpha=0.6,\n",
        "                          path_effects=text_effects, zorder=5)\n",
        "\n",
        "        med_text = plt.text(8.2, 12.5, \"Medium Risk\", fontsize=28, ha='center', va='center',\n",
        "                          color=enhanced_colors['Medium Risk'], fontweight='bold', alpha=0.6,\n",
        "                          path_effects=text_effects, zorder=5)\n",
        "\n",
        "        high_text = plt.text(0.5, 1.5, \"High Risk\", fontsize=28, ha='center', va='center',\n",
        "                          color=enhanced_colors['High Risk'], fontweight='bold', alpha=0.6,\n",
        "                          path_effects=text_effects, zorder=5)\n",
        "\n",
        "        # Add legend\n",
        "        legend_elements = [\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['Low Risk'],\n",
        "                  markersize=12, label='Low Risk', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['Medium Risk'],\n",
        "                  markersize=12, label='Medium Risk', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['High Risk'],\n",
        "                  markersize=12, label='High Risk', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['Medium-High'],\n",
        "                  markersize=12, label='Medium-High', markeredgecolor='black', markeredgewidth=1.5),\n",
        "            Line2D([0], [0], marker='o', color='w', markerfacecolor=enhanced_colors['High-Medium'],\n",
        "                  markersize=12, label='High-Medium', markeredgecolor='black', markeredgewidth=1.5),\n",
        "        ]\n",
        "\n",
        "        legend = plt.legend(handles=legend_elements, loc='upper left', fontsize=10,\n",
        "                          title='Risk Level', title_fontsize=11,\n",
        "                          framealpha=0.9, edgecolor='#d4d4d4')\n",
        "\n",
        "        # Style plot appearance\n",
        "        ax = plt.gca()\n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_visible(True)\n",
        "            spine.set_color('#d4d4d4')\n",
        "            spine.set_linewidth(0.8)\n",
        "\n",
        "        ax.tick_params(axis='both', which='major', labelsize=10, colors='#505050', length=5, width=0.8)\n",
        "\n",
        "        plt.title('Relationship Between High Priority Score and Total Score',\n",
        "                fontsize=16, fontweight='bold', color='#202020', pad=15)\n",
        "        plt.xlabel('High Priority Score (max 9)', fontsize=12, fontweight='bold', color='#303030')\n",
        "        plt.ylabel('Total Score (max 18)', fontsize=12, fontweight='bold', color='#303030')\n",
        "\n",
        "        plt.xlim(x_min, x_max)\n",
        "        plt.ylim(y_min, y_max)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Add note about thresholds\n",
        "        plt.subplots_adjust(bottom=0.12)\n",
        "        threshold_note = \"Risk Criteria: Low: ≥14 total AND ≥6 High | Medium: ≥9 total AND ≥4 High | High: Below thresholds\"\n",
        "        plt.figtext(0.5, 0.02, threshold_note, ha='center', fontsize=9, color='#505050',\n",
        "                  bbox=dict(facecolor='#f5f5f5', edgecolor='#d4d4d4', linewidth=0.5,\n",
        "                          alpha=0.95, boxstyle='round,pad=0.4,rounding_size=0.2'))\n",
        "\n",
        "        plt.savefig('high_priority_vs_total_score.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig('high_priority_vs_total_score.svg', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "#########################################\n",
        "# MAIN FUNCTION\n",
        "#########################################\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the analysis and generate all visualizations\"\"\"\n",
        "    # Initialize style settings\n",
        "    style = PlotStyle()\n",
        "\n",
        "    # Define study data (can be loaded from external source)\n",
        "    study_data = {\n",
        "        'studies': [\n",
        "            \"Patra 2025\", \"Kim 2025\", \"Scherbakov 2025\", \"Rabbani 2024\", \"Shah-Mohammadi 2024a\",\n",
        "            \"Gu 2024\", \"Shah-Mohammadi 2024b\", \"Huang 2024\", \"Roosan 2024a\", \"Fu 2024\",\n",
        "            \"Guevara 2024\", \"Madrid-García 2024\", \"Yu 2024\", \"Peng 2024\", \"Sushil 2024\",\n",
        "            \"Keloth 2024\", \"Kwon 2024\", \"Holmes 2024\", \"Roosan 2024b\", \"Petit-Jean 2024\",\n",
        "            \"Roy 2024\", \"Gabriel 2024\", \"Robitschek 2024\", \"Ralevski 2024\", \"Yao 2023\",\n",
        "            \"Ramachandran 2023\", \"Turchin 2023\", \"Wang 2023\", \"Richie 2023\", \"Bhate 2023\",\n",
        "            \"Kim 2023\", \"Lituiev 2022\", \"Kugic 2022\", \"Botelle 2022\", \"Han 2022\"\n",
        "        ],\n",
        "        'categories': [\n",
        "            \"Error Analysis\", \"Fairness Assessment\", \"Annotation Guidelines\",\n",
        "            \"External Validation\", \"Medical Condition Specificity\",\n",
        "            \"Code/Prompt Availability\", \"Dataset Availability\"\n",
        "        ],\n",
        "        'priority_levels': [\n",
        "            \"High\", \"High\", \"High\",\n",
        "            \"Medium\", \"Medium\",\n",
        "            \"Standard\", \"Standard\"\n",
        "        ],\n",
        "        'max_points': [3, 3, 3, 3, 2, 2, 2],\n",
        "        'scores': {\n",
        "            \"Error Analysis\": [3 if x == 1 else 0 for x in [1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]],\n",
        "            \"Fairness Assessment\": [3 if x == 1 else 0 for x in [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
        "            \"Annotation Guidelines\": [3 if x == 1 else 0 for x in [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]],\n",
        "            \"External Validation\": [3 if x == 1 else 0 for x in [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
        "            \"Medical Condition Specificity\": [2 if x == 1 else 0 for x in [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]],\n",
        "            \"Code/Prompt Availability\": [2 if x == 1 else 0 for x in [1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
        "            \"Dataset Availability\": [2 if x == 1 else 0 for x in [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Prepare data\n",
        "    processor = DataProcessor(study_data)\n",
        "    processed_data = processor.processed_data\n",
        "\n",
        "    # Initialize visualizer\n",
        "    visualizer = Visualizer(style)\n",
        "\n",
        "    # Generate all visualizations\n",
        "    visualizer.plot_domain_completion(processed_data)\n",
        "    visualizer.plot_risk_assessment_heatmap(processed_data)\n",
        "    visualizer.plot_risk_distribution(processed_data)\n",
        "    visualizer.plot_risk_by_year(processed_data)\n",
        "    visualizer.plot_domain_correlation(processed_data)\n",
        "    visualizer.plot_score_scatter(processed_data)\n",
        "\n",
        "    print(\"All visualizations have been generated successfully.\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "jrHmQKg8i9b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmNXFE5ei-XN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}